<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>itkq.jp</title><link>https://itkq.jp/</link><description>Recent content on itkq.jp</description><generator>Hugo -- gohugo.io</generator><language>ja-JP</language><lastBuildDate>Sat, 07 Dec 2019 15:20:22 +0900</lastBuildDate><atom:link href="https://itkq.jp/index.xml" rel="self" type="application/rss+xml"/><item><title>2019年振り返り</title><link>https://itkq.jp/blog/2019/12/07/2019-retrospective/</link><pubDate>Sat, 07 Dec 2019 15:20:22 +0900</pubDate><guid>https://itkq.jp/blog/2019/12/07/2019-retrospective/</guid><description>仕事 2年目 (新卒1.8ヶ月) で引き続き SRE グループで色々をやった。今年は組織やチーム体制が変わったり、メンバーが別のプロジェクトに一時的に参加することになったりということが起きて、これは自分にとってはじめてのことだった。結果、去年までしっかりと理解できていなかった ECS 周りや、自前のバッチ処理システム、非同期ジョブ実行システムといった基盤も運用したり改善することも業務のスコープとなった。基盤勉強会という勉強会を何度かやって大枠をつかんだ後は、業務で必要に応じてコードを読んだり PR を出す過程で理解していった。まだ Fargate は多くのユースケースで実用段階ではなく、大半のコンテナは EC2 で動かす必要があり、それゆえに EC2 インスタンスの管理は ASG や Spot Fleet を使いつつもある程度自前でカバーしていかなければならず、そのためのシステムが多数あることを知って驚いた。このあたりは最近 ASG の機能が増えたり、今後 ECS がよくなっていくことで、いくつかのシステムが不要となりシンプルになっていく可能性はある。
今年の目立った動きとして、サービス開発者の声を拾いプラットフォーム側の改善を行うところは一貫していたと思う。もちろん他のメンバーもガンガンソフトウェアを書いてセルフサービス可能にしているが、未来を見据えたプロアクティブな改善というよりは、現場の声を拾ってそれを咀嚼して改善案を実装しサービス開発者 (と SRE) の生産性を上げるようなリアクティブ性のある動きといえる。ジョブやバッチのログをより高速に (かつ安く) 見れる仕組みを導入したり、依頼が多くなってきた ECS サービスのスケジュールスケーリング機能を内製のコンソールに組み込んだりした。ECS 運用と密接に関係する eagletmt/hako にコミットしたり、社内の hako 拡張に対してのコミットも増えた。社内では、評価を受ける際他人からフィードバックをもらうプロセスがあり、今年はチームメンバーではない外の組織からフィードバックをもらったところ、自分の動きが伝わっていたことを実感できたので良かった。この動きについてはマネージャーからも比較的評価されているところなので、引き続き生産性向上には寄与していきたい。
運用のセルフサービス化に向けて、アラーティングを展開してサービスチームに届ける下地の整備もした。いきなり PagerDuty のアカウントを渡してオンコールになってもらうというやり方ではなく、最初は Slack での通知からスモールスタートすることにした。アプリケーションにチームの Slack チャンネルを紐付け、タスクが不安定・OOM Killed といった ECS レベルのエラーをそのチャンネルに流すようにするところから始めた。通知が多すぎてノイズになったり狼アラートにならないように気をつけ、社内ブログで頻繁に宣伝したり、サービス開発者の Slack チャンネルをウォッチしてアラート対応のサポートをしたりした。同時に Runbook の拡充・布教も行った。最近だと ECS サービスに紐づく ELB の CloudWatch メトリクスに対して、5XX error rate high といった CloudWatch Alarm を低コストで設定できる仕組みを作って、興味のありそうなサービスチームと連携して試してもらったりしている。今では、自分が整備した下地に、RDS のイベント通知など他のメンバーが導入した仕組みが乗っかっていっている状況だ。
オーナーシップを意識して、誰もやっていない領域を拾っていく動きも去年よりはできたと思う。自分がオンコールのときに海外から攻撃を受けて消耗した経験をもとに、攻撃を対処するオペレーションをチャットコマンド化した。金銭コストの事情がありリクエストを弾くのは NGINX と WAF の2つのレイヤーを用意したことで、あらゆるサービスを素早く守れるようにした。実際に攻撃を受けて対処することは複数回あった。また、TLS 証明書の運用がセキュリティグループから SRE グループに引き継がれることになり、引き継ぐ担当になった。まだ引き継いだばかりではあるが、早速有効期限の監視方法を近代化したりしている。必要ならばソフトウェアを書いて可能な限りの運用の効率化をしていきたい。</description></item><item><title>英会話を始めて1年弱で辞めた</title><link>https://itkq.jp/blog/2019/05/04/quit-gaba/</link><pubDate>Sat, 04 May 2019 02:27:15 +0900</pubDate><guid>https://itkq.jp/blog/2019/05/04/quit-gaba/</guid><description>少し長くなってしまったがその経緯をまとめた。
大学院卒業時点 留学経験なし TOEIC 845 (大学2年相当の時) スピーキング: I’m fine thank you and you? レベル ライティング: 英語論文を書いたことがある、それぐらいしかここに書けることがない 語彙: 大学学部程度? + CS Technical terms ￼ 英会話に通い始める (社会人1年目) 漠然と英語をやらねばという気持ちがあったため、会社で流行っていた? マンツーマン英会話 Gaba になんとなく投資してみることにした。会社が法人契約をしていて入会費用が無料になったり、部署の制度で補助が多少もらえた。とはいえ分割で毎月7万ぐらい支払っていて、社会人になって増えた経済的余裕はこれによって破壊され続けた。
喋ると時制や前置詞がとにかくめちゃくちゃ ただし筆記なら正しく書ける… 日本語イントネーションで通じない ほとんどの発音速度は聞き取れるが、たまに聞き取れない 洋画をよく見るようになる (しかし全然聞き取れない) 一言一句聞き取れると楽しい 英会話3ヶ月経過 最初の3ヶ月プランが切れたので6ヶ月プランで再契約した。
何回も間違えるうちに自然な英語を覚えだす 英語喋ってて間違っても今間違えたなと思えるようになる 疑問文の最初や主語動詞を素早く組み立てられるようになる 典型的な挨拶を覚える アメリカ出張 ちょうど仕事でアメリカに行く機会があった。英会話をやっていたので多少は自信がついていた。しかしこれが転機になった。一対一の会話でまず発音が結構通じない。そして全然聞き取れない。英会話はぬるま湯なのだ。よく考えればそれはそうだ。客がすぐさまモチベーションを失って退会してしまうのでは困る。それは一概に悪いとは思わない。しかしこのまま (今の) 英会話に通っても自分が求める結果は出ないことに確信を持った。本当はそんな当たり前のこと知っていた。高い金を払ってマンツーマンで質のいいレッスンを受けようが、レッスン以外の時間も能動的に英語と向き合わなければ上達しないことは。現地で打ちのめされたことによって、長い間目を背けていたその事実に、ようやく向き合うことができた。
目標再考 自分の目標とはなんなのか。ネイティブと普通に普通の会話がしてみたい。これに尽きるのだが、曖昧だしやや高すぎる目標のように客観的には見えた。自分からみるととにかく英語はクールなのだ。このクールは真剣にかっこいいの意だ。漠然と英語に憧れがある。特に会話。世界で通じる言語としてビジネス上習得価値があるのももちろんあるがそれはただの体のいい目標だ。 英語学習の話をすると、技術が発達すれば不要説を返してくる人が結構いる。私は技術は発達してほしいし、翻訳こんにゃくは今すぐ完成してほしいという立場だ。あと何年で自然なリアルタイム翻訳が可能になるか、自分は専門ではないのであまり分からないが、数年はかかると見積もってもいいだろう。その数年で、英語が原因でチャンスを諦める可能性は全く無いのか？自分は大いにあると思った。
英会話1年弱経過 (社会人二年目) レッスン中に自然なフレーズを一口で喋れることがあると嬉しかった。しかしすでに英会話に通うモチベーションはほとんど失っていた。月謝が高いのも大きく影響した。マンツーマンなので、グッと力を入れて教室まで足を運ばなければならないのは、通い始めて1年弱経過、億劫になってもいた。残り1ヶ月レッスンの有効期限があるが、その期限を持って退会することにした。
英会話で得た一番大きいものはリスニング向上とアウトプット瞬発力の向上だった。どちらも著しく向上したとはいえないが。リスニングについては、自分は講師を固定していなかったため、バックグラウンドによる喋りの違いを肌を自身で感じることができた。相手の講師の出身国を挙げると、アメリカ、カナダ、イギリス、フランス、インド、フィリピン、オーストラリアなど。訛った英語 (日本で教育を受けるとアメリカ英語以外はすべて訛っていると思うようになる) は訛っていない英語よりやはり聞き取りにくいが、なんというかこう諦めずに聞けるようになったし以前より聞き取れるようになったと思う。これは経験値の問題。あとは初対面でもこういう英語が来そうという心構えができるようになりこれは会話の理解の初速に大きく影響した。とはいえインド英語は難しい。 次にアウトプットの瞬発力について。これまでの受験勉強なりなんなりによって、時間をかけて文法的に正しい (が英語話者からすると不自然な) 文章を書く能力はあった。しかし喋るのは全然だめ。なぜなら必要なのは会話だからだ。よく英語学習の話で耳にする「脳内で日本語を英語に変換するな」という文句があるが、まさにこれをやっていたのだ。好きな食べ物を聞きたいとして、まず「もの」だから What がくる、相手は you なので what do you like … なんか変だな？みたいな感じだ、おそらく。それが今では、0.</description></item><item><title>第4回 WSA 研究会に参加した</title><link>https://itkq.jp/blog/2019/04/14/wsa-4/</link><pubDate>Sun, 14 Apr 2019 11:20:26 +0900</pubDate><guid>https://itkq.jp/blog/2019/04/14/wsa-4/</guid><description>開催概要: https://websystemarchitecture.hatenablog.jp/entry/2019/02/26/100725
自分の発表 とくに手持ちの実装や実装構想といったものがなかったため、最近よく考えていたカオスエンジニアリングについての整理を試みた。Netflix による &amp;ldquo;Chaos Engineering&amp;rdquo; ペーパーでは、すでにカオスエンジニアリングと同じようなことを Google や Amazon といった企業はすでにやっていることを知っていてそれをカオスエンジニアリングと名付けたと書いてある。その起源は明らかに「レジリエンス」のキーワードに関係していて、レジリエンスエンジニアリングという体系化された学問があることを知った。
レジリエンスエンジニアリングを調べてみると、最近の Web サービスにおける信頼性の考え方、SRE のエッセンスの一部が Safety-II で説明できることが分かった。カオスエンジニアリングはレジリエンスエンジニアリングから来ているかもしれない、というのが直感的に思ったことではあったが、その間には SRE の存在があることは、カオスエンジニアリングの概念が流行する前には SRE の概念の流行があったことを踏まえて自分の中で腑に落ちた。
カオスエンジニアリングに関連する文章でしばしば目にしていた「アンチフラジャイル」が気になったので反脆弱性という本を読んでみた。自分にはまったくなかった考え方が文章で鮮やかに説明されているのを見て感動を覚えるのは久しぶりのことだった。何もしなくても Web システムが平然と動き続けるというのは自分の理想の世界で、そのイメージはポストアポカリプス的な作品で登場する、人類の存在がなくなっても動作し続けるロボットのようなものである。そのように動き続けるためには、レジリエント性だけでは難しいと思っていたなかで、生物には生来備わっているとされる「反脆い」という性質はキーになり得るのではないかと思った。一方で、人類が創造するシステムは、自然の模倣によって進化してきているとある程度言うことができると思っており、自然の限界が人類の限界になってしまうのではないかという漠然とした喪失感も若干感じるようになった。
発表後の議論では、ありがたい意見をいくつかいただいた。概念の説明だけではそもそも議論にならないのではないかという危機感があったものの、そんなことは全くなく、参加者の知識の幅広さ・フィールドの広さを感じた。まず安全工学で語られるフェールセーフやフォールトトレラントという性質はレジリエンスエンジニアリングで語られる Safety-II と本質的な違いがあるかどうかについて。これは自分でも疑問に思っていたことで回答はできなかった。ただ様々な分野から、安全についてまとめられた「セーフウェア」という文献が参考になりそうなことを学んだ。次に反脆いシステムのためには多様性が必要であることについて、リスク分析では多様性を分散として計測することを教えていただいた。そもそもレジリエンスという言葉は様々な学問で登場するようだ。次に多様性によって事故を回避しても「強く」なっているとは言えないのではないか、という指摘。自分は個と組織の視点で分けて考える必要があり、多様性によって弱い種が息絶えることは逆に言えば強い種が生き残ったことになる、と説明した。議論の中で、Web システムだけでなくそれをつくる組織まで広げて考えると、障害を乗り越えていける体制をもつ「反脆い」組織は存在できる、という説明がされた。この説明は最初に自分が考えていたことだった。しかしそれでは結局「機械」だけでは自律できていないことになり、自分の理想とは異なるため別の説明をしたかった。「反脆さ」はまだまだ知ったばかりの概念で、もっと自分で噛み砕いていかないといけない。
他人の発表 月並みだがどの発表も興味深かった。とくに印象的だった2つの発表について書く。
@hirolovesbeer さんのログの分散処理の構想は、最近自分が考えたことに近かった、ので印象的だった。文脈は少し違うのだけど、short-term なログをすばやく見れる方法を考えていた中でのアイディアの1つだった。具体的にはコンテナインスタンスにいる Fluentd のファイルバッファを使い、クライアントがコンテナがいるホストを特定してそのファイルバッファを読みにいくという方法。「ホストを特定して」はディスカバリの問題がある。最近はサービスメッシュの概念が浸透してきて (昔にも似たような構想はいくつかあったというのは知らなかった) ログに対してもそれを使うという説明だった。サービスメッシュはサービスディスカバリの問題、サービス間通信のオブザバビリティの問題、通信設定が分散する問題を全部ひとまとめに解決している、という認識だったために、サービスメッシュと一言で言ってしまうと違和感があったが、サービスディスカバリの上に立つサービスメッシュをもっと色々な場所で活用していくといった発想は今後必要になる気がした。
次に @nari_ex さんの発表。Linux 上でコールドデータとホットデータをいい感じに取り扱う実装の構想。Linux の FUSE や LKM の機能、また SPDK など自分にとっては知らないことがたくさんあって、それを組み合わせるという実装で、オンプレでもクラウドでも使える OSS として実装したいという背景目的も含めて面白いと思った。クラウド時代になってストレージの自由度が低下している、という説明は考えたことがなかったが確かにとも思った。これは自分がストレージをまったくやってこなかったせいかもしれない。自分は仕事の都合上わりと AWS 脳であるために、S3, S3 Standard IA, Glacier を使うと一瞬でできそうだとも思ってしまったが、背景と目的の説明はかなり納得した。
おわりに 参加者を見直してみると研究所の方や大学の研究者ばかりで、客観的に見てかなりレベルの高いことになっている。実際にも議論の質は高いと思う。一企業のソフトウェアエンジニアがこういう場に参加できるのはエキサイティングである一方で、アウトプットへのプレッシャーは高い。学生枠 (?) で第一回に参加していなかったら、そのプレッシャーからその後も参加することはなかったかもしれない。雑に誘ってくれた @yuuki1 さんにはとにかく感謝している。モチベーションになることは間違いないので、プレッシャーをいい方向に働かせていきたい。</description></item><item><title>Slack 上で AWS への単純な bot 攻撃に対処する</title><link>https://itkq.jp/blog/2019/01/12/banacle/</link><pubDate>Sat, 12 Jan 2019 18:46:24 +0900</pubDate><guid>https://itkq.jp/blog/2019/01/12/banacle/</guid><description>業務で使っているインフラ (AWS) に対して、たまに日本のリソースに対して海外の IP からスパムリクエストや明らかな攻撃が来ることがある。リクエスト元 IP が分散していない場合は IP ベースでブロックで十分である。ブロックするレイヤーはいくつかあるが、最近だと VPC の NACL で ban することが多い。NACL の操作を誤ると事故になりかねないので、業務ではセカンドオピニオンも取り入れつつ操作している。攻撃が判明する度に VPC のコンソールを開きつつチャットで誰かの意見を求めるというのは非効率なので、なんらかのソフトウェアを書くことでいい感じにしたいと思っていた。
そこで昨年末に banacle を書いた。雰囲気は README で分かってもらえると思う。Slack の Slash Command と Interactive Message を利用して、セカンドオピニオンを取り入れる仕組みになっている。先日業務で実際に導入してみて結構便利そうだったので記事にした。Approve するユーザを制限する拡張を用意しており、リクエストは誰でもできる一方で SRE 以外は approve できないロジックを足している。</description></item><item><title>Envoy proxy と consul-template を使った Fault injection を試した</title><link>https://itkq.jp/blog/2018/09/12/envoy-consul-template-failure-injection-sample/</link><pubDate>Wed, 12 Sep 2018 23:49:16 +0900</pubDate><guid>https://itkq.jp/blog/2018/09/12/envoy-consul-template-failure-injection-sample/</guid><description>モチベーション サービスメッシュのための Side-car proxy として有名な Envoy proxy (以下 Envoy) がある。Envoy は Observability や Resiliency など便利な機能の他に、Fault Injection 機能を持つ。この Fault injection は、システム全体の可用性を向上させるためのシステム間通信の障害のエミュレートに使われるものであり、これは一般に Chaos Engineering や Resiliency Testing と呼ばれる。
最近 Chaos Engineering に興味があったため、Envoy を使った簡単な Fault Injection を試すことにした。Envoy で Fault Injection をするためには Fault Injection filter を利用する。Fault Injection filter の設定を行えば、「ある upstream に対してリクエストするとき、ある確率で 503 を返す、または (同時に) ある確率でレスポンスを 1 秒遅らせる」といったことが可能である。Chaos Engineering の文脈で Fault Injection を行う場合は、どの程度・どの期間障害を起こすのか設定する必要があり、すなわち Fault Injection filter の設定を動的に変更する必要がある。Envoy には Runtime configuration という機能がある。あるファイルシステムツリーに設定値を書き、Envoy が watch する特定のシンボリックリンクをそのツリーに貼り直すと、Envoy が動的にその設定値を使うようになる、というものだ。Fault Injection filter で設定する値も Runtime configuration による設定が可能である。Runtime configuration 以外にも Listener discovery service (LDS) を使う手もありそうだったが、Listen している socket が変更される cons がありそうだったため今回は Runtime configuration だけ試した。</description></item><item><title>OS ほんのちょっとだけ分かるための JOS</title><link>https://itkq.jp/blog/2018/04/08/jos/</link><pubDate>Sun, 08 Apr 2018 18:27:42 +0900</pubDate><guid>https://itkq.jp/blog/2018/04/08/jos/</guid><description>修論を書き終えたあたりから、春休みに何をするか考えていた。4月からソフトウェアエンジニアとして働き、主にインフラの仕事をする予定だったので、まとまった時間が必要かつ将来役に立ちそうなことを考えた。
ちょうどその頃に turingcomplete.fm を聞いて、OS を学びたい気持ちになった。そうして始めたのが MIT の 6.828: Operating System Engineering の授業である。JOS という xv6 ライクな小さい x86 OS のスケルトンが用意されており、必要な部分を実装していくことが課題である。シェルの動作までを完成させた後、最終課題としてパケット送受信かオリジナル機能を実装して終了ということになっている。
選択した理由 30日OS本も検討していて図書館で借りた。書くべきコードはインターネットですべて入手可能だったため、本を眺めてなんとなく分かった気持ちになって終わる予想ができた。とにかく手を動かしたほうが絶対いいという確信があった。一方 JOS は、OS の動作原理を学ぶものなので、ハードウェアに近い部分の実装は与えられ、Operating Systems Engieering の文脈で重要だとされる部分に集中でき、かつ手を動かす必要がある。まさに自分の求めている題材だと感じた。課題にはテストケースが付属しており、実装が正しいかどうかはある程度確認できることも良い。OS を自作したいというより OS を学びたい気持ちが強かった。
目的 必要が生じた時に Linux のソースコードの該当部分を探して、その内容を理解できるように OS の知識を体系的に得ること
学べたこと 3&amp;frasl;31 までに Lab 5 までを終えた時点で挙げた (粒度は雑)。作業ログ
x86 OS Lab 1: Booting a PC 物理アドレス空間 real-mode, protected-mode kernel 起動までの流れ CPU が起動するとまず BIOS (0xffff0) に jump BIOS は boot sector を (0x7c00 ~ 0x7cff) に読み込み、32-bit protected-mode にスイッチして 0x7c00 に jump して boot loader が起動 kernel を 1 page 分読み込み ELF header を検証し、program segment をそれぞれ読み込む ELF header に埋め込まれた entry point をコールして kernel が起動 Lab 2: Memory Management 物理ページ MMU Virtual address, Linear address, Physical address Page Directory, Page Table Page Table 管理 ページと対応する構造体で参照を管理する Page Directory Entry =&amp;gt; Page Table Entry =&amp;gt; PageInfo =&amp;gt; 物理ページ カーネルアドレス空間 (レイアウトは与えられている) Lab 3: User Environments User-mode environment, または “process“ の状態表現 プロセスの仮想アドレス空間のセットアップ システムコールの割り込みハンドリング Interrupt Descriptor Table (IDT) セグメント毎の privilege level trapframe の表現方法 page fault ハンドリング メモリ保護: アドレス範囲と PTE 属性 Lab 4: Preemptive Multitasking Symmetric Multiprocessing (SMP): 全プロセッサが等価にリソースを触れる Bootstrap Processor (BSP) が他のプロセッサ (Application Processors; APs) を起こす それぞれのプロセッサが割り込みコントローラ (LAPIC) を持ち、LAPIC で各プロセッサを判断する APs は real-mode で起動するため初期化が必要 CPU 毎の kernel stack 領域 big kernel lock (spin lock) spin lock の実体はアトミックに値を交換する命令 xchg 素朴な Round-Robin Scheduling の実体 (プロセスの状態遷移) Unix-like fork() のためのシステムコール、fork の中身 ページマッピングのコピーとCOW属性、User-level page fault handling による Copy-on-Write 再帰的に page fault できるような exception stack を使った仕組み Hardware clock interrupts を使った preemptive multitasking Inter-Process communication (IPC) のメッセージを送受信するシステムコールによる実装 Lab 5: File System, Spawn and Shell セクタとブロック メタ情報を格納する superblocks ファイルに対応するブロックの表現: 直接参照と間接参照によって大容量のファイルも扱うことができる JOS ではカーネルにディスクアクセス機能を実装していないので、ユーザーレベルの environment (プロセス) として実装する ディスク割り込みではなくポーリングを使う Programmed I/O (PIO) ベースのアクセス 仮想アドレスへのファイルマッピングはデマンドページングによるブロックキャッシュ ビットマップでブロックの使用を表現 サーバークライアントモデルのファイルシステムインターフェース “Exokernel” 的な spawn: open して elf を読み込み、fork する。child の trapframe (eip や privilege level ) を設定する file descriptor table のアドレス領域は、PTE を共有することで file descriptor を共有する シェルプロセスの実装 I/O redirection, pipe の実装 プログラミング技術 C言語のポインタ: スタックやメモリを触った途端に理解できる インラインアセンブラ アセンブリレベルの calling convention 学ばなかった (知らなくても課題は解ける) こと ELF フォーマットの詳細 必要以外の x86 instructions QEMU CMOS RAM hardware 詳しく知りたくなったこと Linux のプロセスとスレッドの実装 Linux プロセススケジューリングのアルゴリズム Linux のファイルシステム パーティションの中身 x86_64 との差分 UNIX-style の exec 感想 実際に手を動かしていくと、コードとの対応も取れ理解が進むように思えた。学びたい気持ちはあるけど題材がない場合、このような教材を使って無理やり学ぶという選択肢もアリだなと思った。</description></item><item><title>クックパッド株式会社に新卒入社した</title><link>https://itkq.jp/blog/2018/04/02/join-cookpad/</link><pubDate>Mon, 02 Apr 2018 23:02:18 +0900</pubDate><guid>https://itkq.jp/blog/2018/04/02/join-cookpad/</guid><description>全体会議の自己紹介で、普段は喋れないが酒を飲むと喋れます、そしてこれは社会人になったので克服したいと話したら、その後のウェルカムパーティーで喋れる? 酒飲んでる? と人々が話しかけてくれたので良かった。</description></item><item><title>採用学を読んだ</title><link>https://itkq.jp/blog/2018/03/06/scientific-adopt/</link><pubDate>Tue, 06 Mar 2018 00:24:12 +0900</pubDate><guid>https://itkq.jp/blog/2018/03/06/scientific-adopt/</guid><description>採用学を読んだ。この本では、採用を定義した上で、現代の日本における採用事情の考察・最近の採用手法の変化・より良い採用のための考え方などが述べられており、一読すべき価値のある本だと思う。
この記事では、一応新卒採用を経験した身として、就活時に浮かんだいくつかの疑問を、採用学を読んで上で改めて考えていく。それが正解かどうかは分からない。書き終えてみると当たり前のことを言っているようにも見える。
新卒一括採用が一般的である理由 欧米では必要なときに必要な人材を雇用する「欠員補充」の採用が一般的なのに対し、なぜ日本ではある定められた時期に一斉に次の新社会人が就活をする「新卒一括採用」が一般的なのだろうか。
かつての国立大学は、就職先と密接に関係する、人材育成機関としての意味合い (たとえば旧帝国大学は官界へ、早慶ではビジネス方面へと輩出する) があった。コネクションに基づいた「推薦」による縁故採用 (現代の「学校推薦」とは異なる) であり、大学側と企業側のお互いの信頼関係による就職だったといえる。
定期一括採用が始まったのは今から100年ほど前の最近で、原因は経済成長と大正デモクラシーである、との引用があり、それまでは官界に行っていたような人たちも、銀行といった民間企業に就職し始めたのだという。
しかし「一括採用」の理由としては、本中の説明だけでは不十分に思える。Wikipedia の新卒一括採用のページが詳しかった。
1914年から第一次世界大戦が始まり日本は大戦景気に沸いたが、それによる人手不足から来る就職売り手市場によって学校卒業前に入社選考と採用を行う慣行が始まった[4]。 卒業前の採用慣行は第一次世界大戦後も続けられた。1927年には昭和金融恐慌と、それに続く世界恐慌から学生の就職難が社会問題となった（当時の映画「大学は出たけれど」も参照）。このような恐慌下で、1928年に三井三菱などの大手銀行を中心とする頭取重役の集まりである常盤会の意向により、大学および文部省に働きかけが行なわれ、翌年1929年の学生の定期採用は卒業後に行なうこととする協定が結ばれた[5][6]。就職協定の原型である。にもかかわらず、優秀な学生を確保したい企業による、学生の就職難への不安につけこんだ早期の選考は、この協定後も改まらなかった。その後景気が回復しても企業・学生双方による協定破りは絶えず、ついには1935年6月に三菱の提案で協定は正式に破棄されることとなった[7]。なお、今日まで使われる「内定」という言葉は、この協定によって使われるようになったのだと言われている[8]。つまりは、協定によって「採用決定」が卒業後ということに決められたため、在学中の事実上の採用決定を「内定」と呼ぶことになったのである。
第二次世界大戦終戦後も、大卒者の新卒一括採用の慣習は続いた。終戦直後の卒業生の就職は厳しかったようだが、翌年以降はそれほどでもなかったようである。敗戦という政治・経済状況に極限の変化を迫られる状況下においても、「卒業前の定期採用という慣行は、会社と大学にとってもはや変更不可能なまでに根づいていた[10]」のである。続いて起きた戦後復興と1950年に起きた朝鮮戦争は、日本国内に莫大な特需を生み出し、人手を必要とした企業は多くの新卒者を雇用した[11]。採用の早期化傾向に懸念を抱いた文部省は1953年6月に教育・財界関係者を集め懇談会を開き、「採用試験は10月中旬から1か月くらいとすること」を決定した。これが1996年まで続いた就職協定の始まりである[12]。しかし、就職協定は1996年の廃止に至るまで、ほぼ有名無実な協定であった。抜けがけ採用が発覚しても協定破り企業として新聞に公表されること以外にペナルティーがなく、企業側はマジメに就職協定を守っていては良い学生を採用することができなくなり、学生もそれに従わざるを得ないからである。特に1960年代からの高度経済成長期には更に採用が早期化し、大企業では卒業一年以上前の3年生の採用を決めるという事態にまで発展し、「青田買い」のみならず「早苗買い」「種もみ買い」とまで称されるほどになった[13]。以後も景気状況による変動はあるものの、基本的には在学中に採用が内定する状況は変化していない[14]。21世紀初頭現在においても状況はそれほど変わらず、大学生の就職活動は3年生の秋、9月から10月ごろに始まる。経団連の倫理憲章では、正式な内定日は10月1日[15]とされているが、内定の決定、いわゆる内々定は早ければ4年生になったばかりの春ごろから出され始める場合もある。
要約すると、20世紀の景気の変動と買い手市場によって、就職難の心理につけ込んだ、大学卒業前の優秀な学生の確保が加熱し、これを抑えるために文科省が採用試験の時期を線引した、ということになる。この歴史的経緯が現在でも普遍化しているのだろうが、そもそも大学を卒業したてで普通就労経験のない人間を採用する、「新卒採用」自体の目的はなんだろうか。
新卒採用の目的 就活時に考えていた、新卒採用 (ここでは特に初任給が一律のもの) の目的は、「近い将来成長の見込みがある人材を、手軽な賃金で雇い、会社の文化を十分に吸収させること」のように理解していた。新卒採用は、中途採用と比較して次の特徴があると考えていたからだ。
まだ芽が出ていない (が、近い将来芽が出る可能性がある) (そのため) 給料を安くできる 自社のカルチャーを馴染ませ易い この考えは、本で述べられている採用の1つ目の目的、
(1) 企業の目標および経営戦略実現のため
に近い。もう1つの目標は、
(2) 組織や職場を活性化させる
であり、多様化によって組織が均一化・硬直化することを避けることと述べられている。この2つはあくまで「採用」の目的であり、新卒採用よりも中途採用、すなわち多企業で培われた業務能力・カルチャーを持つ人材のほうが目的を達成するのではないか。
一般的に考えて、優先すべき目的は (1) である。(1) の達成のために人材が大幅に足りない企業、例えば
急激に成長している 従業員数が多い (1000~) ため相対的に離職者も多い は、(1) 達成の手段として新卒採用を用いることは合理的と言えそうだ。選考のプロセスで多様性を考慮できていれば同時に (2) の達成も見込まれる。次に、(2) 達成のために新卒採用をする企業は、
創業年数が長く従業員数もそれなりに多い などが挙げられそうだ。そのため、創業年数が短く従業員数も多くない中小企業 (ベンチャー企業?) が新卒採用を行うのには何か別の目的があると考えられる。
本中で述べられている一般的な新卒採用は、現時点での候補者の実務能力を測れないが故に、実務能力の期待を評価する。しかし、新卒の段階でも実務に直結する能力があれば新卒採用を行う理由として成立する。私が就職先として考えていた IT 業界 (いわゆる Web) では、PC を用いたプログラミングテストや面接でのコーディングが選考フローに組み込まれているのが普通だった。すなわちこの業界の新卒採用は、実務能力の期待しか測れない大部分の新卒採用と大きく体質が異なっている。
ということでなぜ一般的に、また Web の業界で新卒を採用するのか、という疑問は以上で説明できた。なお労働者を違法で酷使するといったいわゆるブラック企業はここでは考慮していない。</description></item><item><title>2017 年振り返り</title><link>https://itkq.jp/blog/2017/12/31/about-2017/</link><pubDate>Sun, 31 Dec 2017 00:51:52 +0900</pubDate><guid>https://itkq.jp/blog/2017/12/31/about-2017/</guid><description>去年の目標はこちら。
就職 「就職先を決める」という目標は、内定受諾という形で達成された。就活を通して、相対的には自分は就活についてよく考えていたようで、表面的な苦労は少なかったように思う。2017 年前半は、就活、ひいては人生を考えることが多かった。自分で独自に考えては、他人にぶつけて意見を聞いてまた考えるということがほとんどで、もっと本を読んだりして、一般的に通じる知識を身につければよかったかなと今になっては思う。
入社エントリはまた書くので詳細はその時に。
研究 「卒業したいので研究をやる」という目標のもと、研究をそこそこやった。業績は、昨年末から含めて、
国内総合大会 1本 (査読なし) 国内研究会 1本 (査読なし) 国際会議発表 1回 (査読あり) 国内英語論文誌 1本 (査読あり, to be appeared) になり、うちの大学の修士学生の平均よりは研究成果があったんじゃないかと思う。ただ、博士行く気無かったもののジャーナルを書くハメになったのは何故…という感じ。ただ将来アカデミックに戻るとすれば役に立つことは確かだ。
修論はまだ手をつけてないけど、これまでの成果をまとめるだけだと思うので多分なんとかなるはずだ。修士の研究としてはだいたいよくやれたという感じだ。
インプット 「本を 30 冊読む」という目標があったようだが、ラノベ・漫画を覗いて数えてみたら 20 冊もいってなかった。読む時間はあったはずなので、これは良くなかった。電車などの隙間時間で技術本を読むのは向いていないというのが分かったのは良しとする。
アウトプット 「いい感じにアウトプットする」という雑な目標だった。ブログと日記の量で見ると、昨年比 +200 % ぐらいになっていて、定量的な観点で相対的にはできていたようだった。対外発表は、WSA 研究会 のみではあるが、内容は充実していたので良かった。今年を通して、アウトプットの重要性を体感した。自分では当たり前のことを書いたつもりでも、褒めてもらえたり、拡散してもらえたりを実感したので、今後も書こうとか書きたいと思ったことは積極的に書いていくつもりだ。
仕事 相変わらず週 2 ぐらいでバイトしていた。ログアーキテクチャ刷新 (WIP), 退職者処理自動化 (WIP), サーバマイグレーションなどに関わっていたものの、特筆すべき大きな成果はなかったので残念。しかし、2015 → 2016 に比べて 2016 → 2017 は、完全に主観ではあるが、知識増加量がだいぶ多かったと思う。就職してからやりたいこともぼんやりと見えてきた気がする。
また、部の新年会から始まり、各種イベント、忘年会と、よく酒を飲むイベントに行った。色んな人と雑に話せるのが楽しくて、自分の知識領域も広がったし、とにかく良かった。
その他 国際会議のために海外に行ったことによって、英語への意識が少し高まり、Netflix を再契約したことにより、結果的に 1 クールあたり見るアニメの量が少し減って、海外映画・ドラマを英語字幕で見ることが増えた。映画を見ることが好きになったし、もう趣味と名乗ってもいいんじゃないかと思っている。
おわりに 来年の目標をぼんやり考えてみたが、自分が長期的な目標を立てて、それをずっと意識して、達成することが難しいことを改めて感じたので、とりあえず今は目標を定めないとする。が、MUST の目標は、
大学院を卒業する 引っ越す である。</description></item><item><title>内定者バイトの是非</title><link>https://itkq.jp/blog/2017/12/24/thinking-part-time-job/</link><pubDate>Sun, 24 Dec 2017 20:49:23 +0900</pubDate><guid>https://itkq.jp/blog/2017/12/24/thinking-part-time-job/</guid><description>僕は内定先でバイトをしているが、内定者バイトではない。
内定者かつバイトというだけで、「内定者バイト」というような特殊な身分ではない。 元々週2 / 時給1500円でバイトをはじめて、その後すぐに時給2000円になった。始めた当初は、大学のほうが結構忙しかったので、週2だけでも働けるという条件だけでかなり嬉しかった。研究が落ち着いてきた後は、週2で研究室の輪講に行き、週3でバイトをする、ようなルーチンだった。大学が忙しいときには今週はすみませんという感じで週0になっていたりかなり柔軟にやらせてもらっていたので、待遇については不満はない。
知り合いから直接聞いた話ではあるが、確かに良くない「内定者バイト」は存在するらしい。比較的安い賃金、研修チックな業務、雑用などなどだ。自分の場合は、研修的な内容は一切無くて（逆に最初は何もわからなかったが）、自分で色々見たりやっていったなかで、こういうのがやりたいとか、部長と相談してこういう大きな課題がある、というように問題意識や課題の発見、解決方針を決める、実際に実装する、というのを一通り自分主導でやるという内容だった。週2のペースだと、業務クリティカルな内容はもちろんできないし、責任も持てないので、業務とは少し外れた、しかしいずれ必要になる問題と戦う、ような内容だった。
内定先にはインターンとバイトの両方ある。インターンは前半が講義な内容で、後半はメンターが付いて、与えられたか、またはある程度自由に課題を発見して、それを解くという内容である。実際、僕のバイトの内容は、インターンの後半に近いと感じており、特別メンターは存在しないが、必要になれば詳しそうな人とか部長と相談の機会を設けてもらったり、設計レビュー、実装レビューもしてもらう。社員は週報で僕の設計レビューと書いていたりしたので、少なくとも自分が所属した部に関しては、バイトには自由に考えてもらって、設計や実装は社員が面倒を見ながら進める、ということが一般的であるようだった。
自分は以上のような環境だったので、内定先でのバイトに全く不満はないし、むしろ全然技術力をはじめとする実力がなかった自分を採ってくれて感謝している。他に良かったことは、自分が飲み会で酒を飲んだり人と話すことが好きというのもあるかもしれないが、社内や部のイベントにも呼んでもらって、すごい社員とか普段話せないような社員の人と雑に会話できたことだ。
また、僕の内定先では、内定者でのバイトは、しなければならないでもなく、したほうがベターでもなく、やりたいならどうぞというスタンスである。僕の場合は、バイトを始めたほうが先で、内定が後で、実際はそういう内定者が多い気がしている。なにかいい感じにバーンとしたいとか、最強になりたいとか考えてはいるが、まずなにから始めればいいのか、みたいに考えている学生は、とりあえず良さそうなインターン・バイトを受けてみるのが良いと思う。自分ももっと早くからまともな職場でバイトしてればよかったと少し後悔している。
もし内定後に内定先でバイトを考えるのなら、待遇、業務内容を調べたうえで、自分がそのバイトで金を稼ぐ以外になにか目的があればやったほうがいい、なければやらなければいい、それに尽きるだけでは、というのが僕の主張である。内定者にバイトを強要してくる会社はまったくもっておかしいので、考え直したほうがいいのではないだろうか。</description></item><item><title>第1回 WSA 研究会に参加した</title><link>https://itkq.jp/blog/2017/12/24/wsa-1/</link><pubDate>Sun, 24 Dec 2017 14:22:45 +0900</pubDate><guid>https://itkq.jp/blog/2017/12/24/wsa-1/</guid><description>開催概要: http://websystemarchitecture.hatenablog.jp/entry/2017/12/17/133301
きっかけ 元々のきっかけは、僕が酔っ払って適当にツイートしてたら、y_uukiさんにいい感じにされてた [Twitter] ことである。y_uuki さんとは一度リモートで会ったことがあったので、じゃあ物理で会いに行こうということになっていた。それとは別に、もともと WSA 研には興味があった。その理由は主に次の2つである。
Web サービスインフラの寿命 最近は Web サービスインフラの可能性について漠然と考えていた。近年、AWS, GCP をはじめとするクラウド、IaaS でサービスを構築することは当たり前になっている。そして、Heroku をはじめとする PaaS, さらには CaaS (Container as a Service) もある。さらに、AWS Lambda に代表される FaaS、つい最近では Serverless Aurora も登場した。インフラを抽象化する流れは加速している。10年先、20年先、もっと先かもしれないが、ごく近い未来、アイディアさえあれば、そのアイディアを実現するインフラ、アプリケーションはボタンを押すだけで構築されるようになっているんじゃないかと妄想している。そうなった場合、インフラをやる人間の仕事は残っているのか。クラウド、プラットフォームを作る側に居ない限り、仕事は無くなっているんじゃないのかとすら思う。どこまで Web サービスインフラがいつまで存在しうるのかに興味がある。
Web システムの限界と学術的価値 Web の用途は広がるばかりであり、最近だとインターネットでテレビをやるみたいなことがある。今のインターネットでは、電波を使ったテレビ局と同じことをやるのは本質的に難しく、限界があるのではないかと思っている。実際には CDN を使うなど実現できる方法はある一方で、Web を使ったシステムのアーキテクチャの限界はどこまでなのかという思いがある。限界があったとしても、それを学術的価値として残せるならそれで十分に良い気がする。Web システムの限界と、学術的価値がどうなっていくのかに興味がある。
自分の発表 参加者全員が発表するレギュレーションだったので発表した。事前に予稿の提出が求められているのは研究会っぽいなとなった。
予稿: https://gist.github.com/itkq/6fcdaa31e6c50df0250f765be5577b59
まとめると、どうやっていい感じにマイクロサービスのコンテナをスケールしていくのという話である。コンテナが究極に早く起動すれば、リアクティブオートスケールと、コンテナを時々ぶっ壊すといった Chaos Engineering を合わせれば解決する気はしている。しかし現実にはそうなっていないので、長期的に見た、最高のスケール、キャパシティプランニングのために、まず1つのサービスのパフォーマンスを数値化し、サービス同士の依存関係も数値化することについて考えた。
待ち行列とキャパシティの関係から考えてみる、本番と同等に再現するなら shadowing は全パターンやらないといけない、その場合 shadowing を受ける先が大変そう、パケットをポートミラーリングすればいいのでは、でも L7 の情報はどうする、など議論が発生して、masayoshi さんにはサーベイのためのキーワードを教えてもらったり、充実していたと思う。構想はあるがなにもできていない、という状況だったので炎上じゃんと思っていたのだが、15 分みっちり議論があったり、おもしろかったと言われたので良かった。今後も自分で考えつつ色んな人と話をしていきたい。
感想 招待講演 tomomii さんの招待講演は、こういう話を話せるということ、こういう話を受けいれる場であったことにまず驚いた。人事でありながら臆すること無く自分の専門外に領域に突っ込んでいくことが凄いし、それを相手に受け入れられるもらえる人柄や雰囲気あってこそだと思った。
個は、東洋哲学の道で生き、失敗をそれでよしとする、失敗を恐れない心構えであることが必要で、組織は、自分の専門領域を極めながらも、専門外の人と議論をしてさらにブラッシュアップし、個が互いに相互し合うことが必要、という内容だと思う。特に専門外の人と話すことによるインスピレーションは、実際に起きていたので驚くばかりである。もともと多数の学部や専門が存在する、大学という機関は、まさにここでいう組織を目指しているものだと改めて思う。しかし、現実には交流がなかったり、しがらみに囚われたり、年功序列の世界だったりする。WSA 研では、大学であるような壁を取っ払って、楽しい・面白いという根源的な動機で、個を増強する組織を目指しているのだなと感じた。参加者全員が発表する、15 分発表 / 15 分質疑のタイムスケジュールも理にかなっている。</description></item><item><title>Vim &#43; LaTeX でいい感じに修論を書く</title><link>https://itkq.jp/blog/2017/11/19/thesis-vim-latex/</link><pubDate>Sun, 19 Nov 2017 02:51:49 +0900</pubDate><guid>https://itkq.jp/blog/2017/11/19/thesis-vim-latex/</guid><description>そろそろ修論を書く季節になった。もちろん Vim と LaTeX で書くつもりだが、ページ数が多くなるとコンパイルに時間がかかって不都合なので、章ごとに分割コンパイルしたいと考えた。 分割した LaTeX ファイルを subfiles を使ってコンパイルする - Qiita が見つかったが、これまで通り Skim で 1 つのファイルをライブプレビューしたかったので、一時的な .tex ファイルを生成してコンパイルする latexmk のラッパーを書いた。
次のようにセッティングしておく。
$ tree -a . ├── .config │ └── latexmk.yml ├── header.tex ├── introduction.tex ├── main.tex └── related_work.tex 1 directory, 5 files $ cat .config/latexmk.yml output_file: output.tex header: header.tex include_files: - introduction.tex - related_work.tex $ cat main.tex \input{introduction} \input{related_work} header.tex には \begin{document} より上の設定を書く。実際のラッパースクリプトは以下。 .config/latexmk.yml がある場合は、いい感じに \begin{document} &amp;hellip; \end{document} を生成してコンパイルする。</description></item><item><title>BBR: Congestion-Based Congestion Control とは</title><link>https://itkq.jp/blog/2017/07/31/bbr/</link><pubDate>Mon, 31 Jul 2017 22:30:43 +0900</pubDate><guid>https://itkq.jp/blog/2017/07/31/bbr/</guid><description>最近 TCP BBR congestion control comes to GCP – your Internet just got faster が話題になっていた．しかし，この記事を読んだ時点での自分の BBR についての知識は，「既存のものよりいい感じにしてくれる輻輳制御」ぐらいだった．これではまずいということで，BBR とはなんなのかについて，既存の輻輳制御にも触れながら，元の論文1 をメインにまとめた．自分が理解するための文書であるが，一応としての想定読者は，TCP が輻輳制御を行っていることを知っているぐらいの人である．TCP については，拙著の TCP/IP とパフォーマンス に短くまとめてあるので参照できる．
免責事項:
TCP を深く研究しているわけではなく，間違いを記述している可能性があります．コメントで教えていただけると助かります．
概要 BBR (Bottleneck Bandwidth and Round-trip propagation time) とは，Google が開発した新たな TCP 輻輳制御アルゴリズム．2016年9月に Linux Kernel に取り込まれ，論文は2017年2月に公開された． 既存の輻輳制御とは異なる輻輳検知，観測と推定をループするシステムモデルのアプローチにより，現代のネットワーク環境において高スループット，低レイテンシを発揮する．
背景 今日，Linux の TCP 輻輳アルゴリズムとして広く用いられているのは CUBIC2 であるが，loss-based (パケットロスを輻輳の判断に用いる) の原理自体は 1970 年代の TCP の誕生から変わっていない．しかし，ネットワークやスイッチの進化により，輻輳を回避するためのこの方式が Bufferbloat というパフォーマンス問題を引き起こすようになった．Bufferbloat は，本質的には Loss-based 輻輳制御アルゴリズムの性能限界を示していた．輻輳を回避しながらも，最大スループットと最小 RTT の達成を目標として設計されたのが BBR である．
Bufferbloat Bufferbloat とは，非対称な帯域幅のリンクに挟まれたスイッチが引き起こすキューイング遅延による， End-to-End のレイテンシ増加のことをいう． 実際の &amp;ldquo;bloat&amp;rdquo; (むくみ) は，大きい帯域幅から小さい帯域幅へ向かうときに起こる3． 分かりやすい例として，以下の (極端な) last mile で考える．Router にはパケットを貯める送信 FIFO バッファ (以降 bottleneck queue とも書く)がある．</description></item><item><title>TCP/IP とパフォーマンス</title><link>https://itkq.jp/blog/2017/07/16/tcpip-performance/</link><pubDate>Sun, 16 Jul 2017 19:44:55 +0900</pubDate><guid>https://itkq.jp/blog/2017/07/16/tcpip-performance/</guid><description>この文章は、ハイパフォーマンスブラウザネットワーキングを読んで、改めて TCP/IP を自分の中で整理し、パフォーマンスに関する内容を簡単にまとめたものである。 情報通信ネットワーク特論を受講しておりタイミングが良かったという理由もある。
IP IP は、パケット交換によるデータ通信網を実現するためのプロトコルである。The Internet ができる前は、Hop-by-Hop（中間ノード間）で信頼性を確保していた。TCP/IP は、経路到達性と信頼性を IP と TCP の形で分離したプロトコルスイートである。この分離により、複雑なトランスポート機能はエンドシステムだけで行えるようになった。このような設計思想は End-to-End Principle と呼ばれる。
TCP TCP は コネクション指向であり、Go-back-N ARQ を基本とする輻輳制御プロトコルである。 コネクション指向通信とは、実際にデータをやりとりする前に、通信を確立する通信である。TCP では、three-way handshake を用いてコネクションを確立する。 シーケンス番号と確認応答番号やチェックサムを使った高品質な伝送のための再送制御は、データ通信網においては必須の機能と言え、TCP の本質的な部分ではない。TCP の本質的に重要な役割は、フロー制御と輻輳制御である。 TCP は、ウィンドウによって上記2つを同時に達成している。
フロー制御 フロー制御は、受信側が処理できるペースで送信するエンドツーエンドのメカニズムである。TCP では、スライディングウィンドウでフロー制御を行う。受信側は送信側に受信ウィンドウサイズ (rwnd) を広告する。通信中は動的にウィンドウサイズを変更できる。
輻輳制御 IP では、データをパケットの単位で交換する。パケット網での輻輳とは、ネットワーク上のパケット量が許容値を超えて、パケットが正常に配送されなかったり、遅延する現象のことである。パケット交換は、実際にはルータが行う。ルータはパケット処理のために多少のバッファがある。パケット過多の場合、バッファにはパケットが累積し、これが遅延となる。また、バッファが一杯の場合、パケットは破棄される。慢性的に輻輳し、エンド間ではパケットを再送する処理をした場合、更に輻輳が悪化する。この現象は輻輳崩壊と呼ばれる。輻輳を防ぐ、または回避するためのメカニズムが輻輳制御である。TCP ではパケットロスを輻輳検知に利用して、輻輳を回避する制御を行う。
スロースタート フロー制御だけでは、ネットワーク自体の許容量を制御できず、輻輳が起こる。通信中に、ネットワークの利用可能な帯域幅に調整する必要がある。利用可能な通信容量を推測する唯一の方法は、実際に送受信をすることである。 TCP 接続毎に輻輳ウィンドウサイズ (cwnd) を初期化し、控えめな値からスタートする。
輻輳制御アルゴリズム スロースタート後は、ACK が帰ってくるたびにウィンドウサイズを大きくする。実際に使用されるウィンドウサイズは、min(rwnd, cwnd) である。TCP では、ウインドウサイズを指数的に増加させる。どこかのタイミングでパケットロスが発生した場合、cwnd を引き下げることで、パケットロスを最小化させる。このときに動作するウインドウサイズを調整するアルゴリズムはいくつかあり、オリジナルは TCP Reno、Linux のデフォルトは TCP CUBIC である。
TCP のパフォーマンス 主に Web ブラウジングのために考慮すべきパフォーマンス事項と Linux での設定。
ウインドウサイズ スロースタート (initcwnd) の緩和 RFC 793: 1 セグメント (MSS; Ethernet だと 1500 Byte) RFC 2581: 最高 4 セグメント RFC 6928: 最高 10 セグメント (Linux 3.</description></item><item><title>新卒就活を終えた</title><link>https://itkq.jp/blog/2017/07/13/get-my-first-job/</link><pubDate>Thu, 13 Jul 2017 00:30:23 +0900</pubDate><guid>https://itkq.jp/blog/2017/07/13/get-my-first-job/</guid><description>TL;DR 新卒就職活動を終了したので供養をする 社会に出る前にやれることをやるぞ 会社を選ぶ 会社を選ぶ上で考えたことを書ける範囲で書く。 以下に登場する「エンジニア」は、大体ソフトウェアエンジニアのことを言っている。 「Web 系」という言葉は結構適当に使っている。
面白い仕事か 私はプログラミングは好きだけどそう自信はないし、実績もなく、コンピュータサイエンスと数学の知識は大学の学部卒業程度だと思う。 しかし、急激な速度で進化していて世界を変える潜在的な力を持つソフトウェア、Web サービス、インフラといった分野が好きで、 結局はそういうことに関われる会社に決めた。 これまで20年以上生きてきて、ずいぶん狭い世界で生きてはいるが、昔から面白いと思っているので、 この考えはとりあえずすぐには変わらないだろう。
私はいわゆるインフラをやりたいと思っている。 バックエンドやフロントエンドにしても、TCP/IP が分かってメモリや CPU の気持ちを分かっていたほうが結局は良いコードが書けると思う。 であれば下のレイヤーから始めれば色々と都合が良いのではないかという考えがあった。 少しずつではあるが実際に学んでみて、しっくりきたことも多いし、面白いと思うようになり興味を持った。
ところで、Web 系に行くのに修士まで取る必要があるのだろうか。逆に言えば修士卒で Web 系に行く意味はあるのか。 十分あると思う。これは実際に働いている人を見て感じたことでもあるし、 数年で技術のスタンダードが大きく変わってしまうようなこの業界では、 世界市場で競争する上で、本質的な要素を追究する研究という要素は必要だと思っている。 修士の研究テーマ自体は役に立たないかもしれないが、培った研究のエッセンスは新しい技術やアーキテクチャを考える上で、それらが本質的に新しく役に立つものなのかを見抜くのに役立つはずだ。
思えば就活を始めた頃、適当にこなせてそこそこ給料がもらえる会社に就職したいと思っていた。 しかしちょっと考えてみると、平均寿命まで生きれば、働かなかった期間よりも働いている期間のほうが長い。 楽にこなせるが面白くない仕事を、これまでの学生生活より長く、「食べるため」だけに、果たして本当にできるのだろうか。 いや実際には歳をとるほど体は動かなくなって、楽な仕事を求めるようになるのかもしれない。 しかし少なくとも今は、自分が面白いと思うこの業界で働きながら、その進化を間近で見ていたいと思った。 まあ一発当てて早々に隠居できれば一番良い。
技術は評価されているか カンファレンスや勉強会、OSS などを通して現社員が外に発信しているかどうかを気にした。 発信のレベルが高ければ単純に技術力が高いということにも繋がるが、単に外に出て発信している、という行為自体も評価されるならば、そういうモチベーションもあるだろうと思う。 エンジニア出身のマネージャーが技術力を評価したいのは当然だと思うが、 組織全体として評価するならば、いわゆる経営陣が、技術力が事業に直結する重大な要素だと思っていなければそうはならない。
自分が外に対してバリバリ発表をしてそれを評価されたい、と言いたいわけではない。 オープンソースコミュニティ、エコシステムといった業界の流れに逆らっていないか、つまるところ技術で勝負する気はあるのか、ということである。 技術が目的になってしまっては本末転倒である一方で、最適な技術選定をしてそれを本番で使うためには、技術に対するポジティブな心構えがあったほうが良い。
また、これはエンジニアの立場に直結すると思っている。広い意味で、エンジニアにとって働きやすい会社が良いと思った。 インフラの立場では、インフラは動くのが当たり前という考えのもと、減点法で評価されるのは避けたい。 もちろんインフラは動いていた方が良いが、時に動かなくなってしまうことが絶対にないとは言い切れない。 インフラは一朝一夕には改善されないが、ただ運用するのではなく、改善のために努力できる環境が良い。 例えば、レガシーなアーキテクチャを繊細な検証の上に一新して、パフォーマンス向上やコスト削減によって長期的なビジネスの成功に貢献した時、それがきちんと評価される組織が良い。
やりたいことを見つけられるか 私はインフラ、具体的にはミドルウェアやサーバ構成管理、運用、自動化あたりをやりたいと思っていて、 かつ最近のトピックである SRE は自分も共感し興味がある。 しかし、インフラの中でも色々ある領域のうち、現時点でこれをやりたいとかこれが好きだというのは、 多少はあるが明確には決められていない。
これは新卒では許されることだと思っている。 ある分野のプロフェッショナルになるのかまたはオールラウンダーになるのかなど、自分の強み、または市場価値を見つけることが必要になるが、 私にはそれがないので、見つけるために私はまず企業という環境で色々試してみたい。 そのために、試せる組織、文化、環境であってほしい。 例えば、技術領域的に細分化された部署で働けば、（思い込みかもしれないが）普通は何かに尖った人になるだろう。 これが本人が望んだ分野または得意な分野であれば良いが、違う場合は幸せなのだろうか。 そのチームには望んで配属されたのだろうか…。 私はそういうリスクを避けて、横断して広い範囲を見ることができるチームで働きたいと思った。
その他 すごいと思う先輩はいるか インターネット的な話が通じるか 待遇は悪くないか 自分の身の丈より逸脱していないか なんかチャラくないか やっていく感じがあるか オタクが迫害されていないか 実際の就活 去年の11月ぐらいに、逆求人があるので来ませんか、とインターネットでいきなり誘われた。 逆求人に対しては正直ポジティブではなかった。逆求人は意識が高まった人たちが行くものと思っており、私は高まっていなかったからである。 しかし実際にやってみると逆求人は価値があると感じた。 多くの人が言うように、充実した時間になるがその分疲れるのは本当で、 自分の場合最後の方は口が回らなくなったりした。なので普段から人間と喋っておいたほうが良い。</description></item><item><title>Linux におけるファイル I/O の基礎</title><link>https://itkq.jp/blog/2017/05/10/linux-file-and-io/</link><pubDate>Wed, 10 May 2017 16:11:33 +0900</pubDate><guid>https://itkq.jp/blog/2017/05/10/linux-file-and-io/</guid><description>すべてがファイルというモデルの Linux (Unix) において、ファイル I/O (以降単に I/O と書く) を知っておいて損はない。 この記事では、基本的なファイルと関連する I/O について、対応する Linux システムコールも併せて説明する。 次回はこれらを実際に Linux 上で確認する予定。
ファイル Unix におけるファイルとは、普通「通常ファイル」のことを指し、バイトがリニアに並んだデータ (byte stream) のことである。 ファイル内のバイトは読み書きが可能で、指定されたバイトから開始する。この開始バイトはファイル内の「位置」と考えることができ、ファイルポジションまたはファイルオフセットという。
通常ファイルとは別に、スペシャルファイルというファイルとして表現されたカーネルオブジェクトがある。Linux では、スペシャルファイルとしてデバイスノード・名前付きパイプ・ソケットに対応している。名前付きパイプは、FIFO とも呼ばれ、プロセス間通信 (IPC) に使われるファイルである。ソケットは歴史的にも特殊なので、またの機会に説明する。
ディレクトリとリンク Unix におけるディレクトリは、単にファイル名と対応する inode 番号のリストを保持するものである。ディレクトリが保持するファイル名をディレクトリエントリ、またファイル名と inode の対応をリンクと呼ぶ。
複数のリンクが同じ inode 番号を指すことも可能である。複数リンク間で、どのリンクが「主」や「元」という概念はなく、すべてのリンクは平等に扱われる。このようなリンクをハードリンクという。ファイルは任意の数のリンクを持つことができる。通常ほとんどのファイルのリンクカウントは 1 であり、1つのディレクトリエントリが1つの inode を指す。 ハードリンクの追加は link(2) で行える。
リンクの種類には、シンボリックリンクもある。シンボリックリンクは、ファイルシステムがマッピングするものではなく、実行時に解釈される、より上位で処理されるポインタである。 実際には、ディレクトリエントリ追加ではなく、特殊な型を持つ専用ファイルである。 この専用ファイルは、他のファイルのパス名を格納するもので、これをシンボリックリンクのターゲットという。シンボリックリンクのパス名は、実行時にカーネルにより参照先へ置換される。 ハードリンクと異なり、シンボリックリンクはファイルシステムに跨って作成することが可能で、また存在しないファイルに対しても作成可能である。対応するシステムコールは symlink(2) である。 リンク作成の反対は、アンリンク、すなわちパス名の削除である。unlink(2) が対応する。 ディレクトリを削除するには rmdir(2) を用いる。
デバイスノード Unix におけるデバイスへのアクセスはデバイスノードというスペシャルファイルを介して行われる。 アプリケーションから、デバイスドライバへアクセスするためのデバイスノードに対してファイル I/O を行うと、カーネルは通常のファイル I/O として処理せず、要求をデバイスドライバへ渡す。 デバイスノードはデバイスを抽象化したもので、Unix システムでハードウェアにアクセスする際の標準的なインターフェースとなっている。この設計は、マシン上のハードウェアを統一的に操作できるという美しいインターフェースであり、Unix の大きな功績の1つである。ただし、ネットワークデバイスだけは例外である。 カーネルは、メジャー番号とマイナー番号というデバイスドライバに割り当てられた2つの数字を用いて、カーネル内にロードされたデバイスドライバにマッピングすることにより、要求された処理をどのデバイスドライバに渡すかを決定している。</description></item><item><title>Unix 以外のオペレーティングシステム</title><link>https://itkq.jp/blog/2017/05/01/operating-system-comparison/</link><pubDate>Mon, 01 May 2017 15:14:42 +0900</pubDate><guid>https://itkq.jp/blog/2017/05/01/operating-system-comparison/</guid><description>Unix 以外の簡単な歴史と特徴をまとめる。
MacOS Macintosh OS は、先駆的な GUI 研究に刺激されてた 1980年代初期の Apple 社で開発された。世に出たのは 1984年の Macintosh 発売と同時である。
MacOS は、Mac インターフェースガイドラインという Unix とは大きく異なった思想を持つ。ガイドラインはアプリケーション GUI の表示と動作を詳細に規定している。特に重要なのは、「何かを置いたらそのまま残る」ところである。デスクトップ上のオブジェクトの位置は再起動後も維持される。すべてのプログラムは GUI を持つ。
設計者の意図した Macintosh の役割は、技術者ではないエンドユーザーを対象とするクライアントオペレーティングシステムである。
近年、古典的な MacOS はその生涯を終えた。MacOS X は、古い OS のほとんどの機能を取り込んだ上で、バークレーの伝統から派生した Unix OS に融合した。実際には、Darwin というオープンソース Unix カーネルの上に2つのプロプライエタリレイヤ (OpenStep と Mac GUI) を乗せた形になっている。MacOS は UNIX として認証されたオペレーティングシステムである。
Windows NT Windows NT (New Technology) は、Microsoft の個人用ハイエンド OS またはサーバ用 OS である。NT は付け足しの連続で成長しているため、Unix の「すべてはファイルだ」やMacOS のデスクトップにあたる基本思想を持っていない。強いて言えば「ユーザは閉じ込めておかなければならない」である。NT オペレーティングシステムのターゲットユーザは主として技術者ではないエンドユーザである。
DOS (1981), Windows 3.1 (1992), Windows 95, Windows NT 4 (1996), Windows 2000, Windows XP (2002), Windows Server 2003 という各世代を経るたびに、基本的な部分が変化してきた。古い方法は時代遅れとみなされ、サポートも打ち切られる。</description></item><item><title>Unix の歴史と思想</title><link>https://itkq.jp/blog/2017/04/30/unix-history-and-principle/</link><pubDate>Sun, 30 Apr 2017 22:17:37 +0900</pubDate><guid>https://itkq.jp/blog/2017/04/30/unix-history-and-principle/</guid><description>これは、自分がプログラミングを始めた頃に読みたかった（読むべきだった）というつもりの文章である。
Unix の歴史 Linux 登場までの歴史を簡単にまとめた。省いているところも多い。
Unix の誕生 ベル研究所の Ken Tompson が、1969年に開発したゲーム用プラットフォームが起源である。当時はメインフレームで動く TSS が実験されていた (Multics) が、大規模で複雑なプロジェクトだった。 ベル研究所は Multics プロジェクトから脱退したが、彼らは対話的コンピューティングを必要としていた。その後ゲーム開発を可能にするプログラム（＝カーネル）が生み出された。これが Unix の元となった。Unix の語源は、Multics (Multiplexed information and computer system) を意識した UNiplexed Information and Computer System だと言われている。
ワードプロセッサをサポートする過程で、Unix OS が誕生した。初期の Unix OS はアセンブリ言語で書かれていたが、後に移植性を高めるためにC言語、つまり高水準言語で書き直された。 この頃は主に DEC (Degital Equipment Corporation) の PDP-7 というミニコンピュータで Unix は稼働していた。
1970年代に、Unix についての論文が ACM に投稿されたことで、世界中の研究機関が Unix に興味を持った。ベル研究所の親会社である AT&amp;amp;T は、電話と関係ない技術だったために、Unix のソースコードを配布することになった。
BSD Unix ARPANET は、インターネットの起源となった、複数の研究機関を接続したパケット交換ネットワークである。Unix と同時期の 1969年から開始された。当時 ARPANET は PDP-10 で稼働していたが、次世代の VAX シリーズ生産とともに淘汰されつつあった。そこで VAX 上の Unix で動作する TCP/IP プロトコルスタックの実装が必要になった。初期の Unix のネットワークサポートはごく貧弱だった。</description></item><item><title>itamae コードリーディング</title><link>https://itkq.jp/blog/2017/03/19/itamae-reading/</link><pubDate>Sun, 19 Mar 2017 19:25:53 +0900</pubDate><guid>https://itkq.jp/blog/2017/03/19/itamae-reading/</guid><description>元々は NeoVim を導入しようとしていた．その一環で，dotfiles を良い感じにしようとしていて，mitamae によるプロビジョニング設定の k0kubun/dotfiles から fork したものを整理していた．NeoBundle の NeoVim 対応版である dein.vim を導入する際，curl が必要だった．itamae の Resource ドキュメントを読むと，http_request というリソースがあった．これ使えば Docker の ADDコマンド的なことできるのかなと思ったけど詳細が書いてなくて，そういえば itamae 自体どうやって動いてるんだと気になったので読むことにした．
itamae-kitchen/itamae/
Code reading bin/itamae Itamae::CLI.start を呼ぶ．
lib/itamae/cli.rb Itamae::CLI は CLI gem Thor を継承している． 実行環境 (backend_type) は3つあり，local, ssh, docker である．必要としていて，かつ他より単純そうな local を続けて読む．
def local(*recipe_files) if recipe_files.empty? raise &amp;quot;Please specify recipe files.&amp;quot; end run(recipe_files, :local, options) end def run(recipe_files, backend_type, options) runner = Runner.run(recipe_files, backend_type, options) if options[:detailed_exitcode] &amp;amp;&amp;amp; runner.</description></item><item><title>SQL実践入門 読んだ</title><link>https://itkq.jp/blog/2017/03/15/sql-practice/</link><pubDate>Wed, 15 Mar 2017 19:19:27 +0900</pubDate><guid>https://itkq.jp/blog/2017/03/15/sql-practice/</guid><description>メモです．
3章 式の条件分岐 SQLのパフォーマンスは，テーブルスキャンによる I/O を減らすことが重要． 手続き的な WHERE, UNION による条件分岐，テーブルフルスキャンが複数回行われる．同テーブル内では，SELECT 句で CASE WHEN で条件分岐させるとクエリの可読性，実行計画共に良くなることあるので，考えなしに UNION を使うのは危険． ただし，インデックスが使える場合は，「UNION による複数回のインデックススキャン」と「OR または IN による1回のフルスキャン」の勝負になり，UNION の方が速い場合もある． 4章 集約とカット GROUP BY には「集約」と「カット」の機能がある．「カット」とはパーティションをつくること．ウィンドウ関数の PARTITION BY はカットのための機能．
最近のオプティマイザは，GROUP BY による集約は，指定された列のハッシュ値によってグループ化している．古典的なソートより高速である． GROUP BY では，ハッシュかソートいずれの場合でも，メモリを多く使用するため，ワーキングメモリを使い切ってしまうこと（TEMP落ち）に注意． SELECT 句で指定するキーと，GROUP BY 句で指定するキーを同じくすることでカットできる． 5章 手続きSQL SQL実行のオーバーヘッド：
SQL文のネットワーク伝送
データベースへの接続
SQL文のパース
SQL文の実行計画生成および評価
結果セットのネットワーク伝送
1と5は，同一ネットワーク上であればほぼ無視できる．2はコネクションプールで対応できる．このうち，3と4が支配的である． ある処理を達成するために，逐次的な「軽いSQL」によるロジックと，一度の「重いSQL」によるロジックがある．
軽いSQLによる問題：
DBのストレージは普通RAIDで構成され，I/O負荷を分散できるが，軽いSQLは，並列分散による恩恵が受けづらい
DBは，重いSQLを高速化するように進化する．軽いSQLはそもそもチューニングポテンシャルがない
一方で軽いSQLの利点：</description></item><item><title>About</title><link>https://itkq.jp/about/</link><pubDate>Fri, 17 Feb 2017 18:42:21 +0900</pubDate><guid>https://itkq.jp/about/</guid><description>Software Engineer. Likes automation and animation. Interested in SRE and Chaos Engineering.
Experience Apr. 2018 - in present Software Engineer (SRE group) @ Cookpad Inc. Dec. 2016 - Mar. 2018 Part-time Software Engineer @ Cookpad Inc. Education Apr. 2016 - Mar. 2018 Masters of ICE @ Tokyo Institute of Technology Apr. 2014 - Mar. 2016 Bachelor of CS @ Tokyo Institute of Technology Certification Aug.</description></item><item><title>Fluentd syntax for vim 書いてる</title><link>https://itkq.jp/blog/2017/01/03/fluentd-syntax/</link><pubDate>Tue, 03 Jan 2017 17:54:56 +0900</pubDate><guid>https://itkq.jp/blog/2017/01/03/fluentd-syntax/</guid><description>Fluentdを書く機会があったのだが、Vimがシンタックスハイライトしてくれなかった。
あれーと思ったけど vim8の新機能 にもFluentdの記述はなかった。
&amp;ldquo;vim fluentd syntax&amp;rdquo; で検索すると、 https://github.com/yoppi/fluentd.vim がヒットするが、Latest Commit が4年前だったのと、自分で使ってみて馴染まなかったので、自分で書いてみている。
itkq/fluentd-vim
vimのhelpを読みつつ、とりあえずできた状態。
そのうちガッツリFluentdを書くことになりそうなので、アップデートしていきたい。</description></item><item><title>2017年の抱負</title><link>https://itkq.jp/blog/2017/01/03/2017-goal/</link><pubDate>Tue, 03 Jan 2017 15:52:28 +0900</pubDate><guid>https://itkq.jp/blog/2017/01/03/2017-goal/</guid><description> 去年 だめだめ
やりたかったこと 英語
やれてない 日経ニュースを英語で聞ける LissN を聞く時期があったけど、忙しいとか言い訳してたら習慣が終わった 関数型プログラミング
やれてない プログラミングの基礎を読んだ Scala関数型デザイン&amp;amp;プログラミング Scalazコントリビューターによる関数型徹底ガイドでつんでる 学部卒業
やれた やってたこと インターンにいかずに研究を進めた 就活っぽいやつ やっていき 反省 春休み何をやっていたのか記憶がない やれてない 今年 とりあえず
やること 就職先
きめる 研究
卒業したいので研究をやる インプット
去年は計15冊程度しか読めなかったので、今年は倍読む アウトプット
不寛容社会とエンジニアの「正しさハラスメント」 読んだ。ここはインターネットなので、言い方や伝え方は様々ある 批判や否定があることも意識しながら恐れずにアウトプットする必要がある 自分も、ブックマークがたくさん付いた記事を読んで、しょうもないなって思うことがあるけど、読んでもらうことに意味があると思うようにしたい ブログ書く OSS やっていきたい</description></item><item><title>ウェブオペレーション 読んだ</title><link>https://itkq.jp/blog/2017/01/03/web-operations/</link><pubDate>Tue, 03 Jan 2017 15:30:11 +0900</pubDate><guid>https://itkq.jp/blog/2017/01/03/web-operations/</guid><description>結論としては、勉強になったし読み物として面白かった。
オペレーションに関係するソフトウェアの特徴・比較・使い方の詳細な記述はないが、 それらの関わりが簡潔にまとめられているおかげで、体系的な理解の助けになった。
この書籍は18の章から成っており、それぞれ著者が異なる。
ある章の結論が他の章の結論を直接的に否定しているわけではないが、 全体的には、ただ一つの正解は無いと言っているようで、考えさせられた。
内容が豊富で、すべては噛み砕けていないので、また読む。
データベース データベースは、難しいということが分かった。
データベースは特にボトルネックになりやすく、またバックアップが必要である。一般的なマスタスレーブ構成の場合、スレーブへの非同期レプリケーションは厳密には一貫性を失うし、マスタ冗長化もまた一貫性を失う。
じゃあクラスタリング、とはいかなくて、ウェブデータベースのユースケースに適したクラスタはないと書かれている。2016年現在も無いのかどうかは、ちょっとわからない。
CAP定理は、Consistency, Availability, Partition Tolerance の3つを同時に達成できないことを示す。 データを複数サーバに分割した場合、トランザクションの信頼性を保証するACID (Atomicity, Consistency, Isolation, Durability) 特性は失われる。また、分散トランザクションは通信障害の影響から確実性が保証されていない。
スケールが可能なNoSQLの採用も考慮すべきである。 NoSQLにも、アーキテクチャの違いから、色々ある。
Redisとmemcachedしか触ったことがなかったので、とりあえず他の種類と特徴ぐらいは覚えておきたい。
データベースアーキテクチャに正解はないので、論理的な選択が必要。
DevOps この本は2010年に出版されたものだが、2010年にもうDevOpsという言葉があったことに驚いた。
&amp;ldquo;DevOps&amp;rdquo;という単語が初出の発表(2009)では、開発と運用が互いのことを思いやるために、6つのツールと4つのカルチャーが挙げられていた。
10+ Deploys Per Day: Dev and Ops Cooperation at Flickr de John Allspaw
自分の中では、DevOpsがすでに当たり前として受け入れてしまっているが、 これらのツールやカルチャーが無かった頃、そもそもなぜ開発と運用は分かれていたのだろうかと思った。 開発と運用が衝突する構図自体は理解できる。
雑に調べてみると、ITの内部統制によって、適切な権限管理の観点から、開発と運用を分離することが義務付けられているらしい。
アジャイル開発が積極的に用いられるようになってから、とにかく速くサイクルを回すために、自動テスト・継続的デプロイ・メトリクス可視化などの技術が発達し、それらの技術を共有するためのカルチャーも含めたプラクティスをDevOpsと呼ぶようになった、という感じなのだろうか。
最高のオペレーションとは アーキテクチャの設計では、その設計が5年後動作するのかを考えなければならない、と言っていた。 しかし、データベースアーキテクチャ設計では、シャーディングのような、将来のスケールを見越したアーキテクチャは、可能な限り使うな、と。
また、複雑なシステムは本質的に危険なので、シンプルにすべきであると言っている。しかし、「シンプル」なデータベースアーキテクチャは、現実的ではない、とも言っている。
すなわち、汎用的に正解であるアーキテクチャは存在しないということなのだろう。 あるシステム特有のアーキテクチャにするのが正解だと。 あれもこれもやりますみたいにサービスが進化していくのは良くない。
結局どう決めればいいのかは、SLAに基づく運用ポリシーよる。 するとSLAの決め方が重要になってくる。
Webシステムに必要なのは「一貫性」ではなく「可用性」と結論づけていた。 まずは顧客を継続的に留めることが重要である。 また、レスポンスタイムは顧客の印象評価に直結することが示されている。
ビジネス、マーケティング目線のメトリクスももちろん必要。 これらのメトリクスをベースにしてSLAを決定する。
オペレーションの仕事は、全てのアーキテクチャを正常に運用し、収集したメトリクスをステークホルダに翻訳すること。 ウェブオペレーションは、常に危険があり、「絶対」はない。 つまり、本質的には進化は無限に続くということで、 日々発展する技術、アーキテクチャ、メトリクスをキャッチアップする必要がある。</description></item><item><title>SQLアンチパターン 読んだ</title><link>https://itkq.jp/blog/2017/01/01/sql-antipattern/</link><pubDate>Sun, 01 Jan 2017 12:38:21 +0900</pubDate><guid>https://itkq.jp/blog/2017/01/01/sql-antipattern/</guid><description>インターネットに読めと言われている気がしたので読んだ。
論理設計 一意性と参照整合性に留意する。交差テーブルや従属テーブルを導入する。これは理解できた。
個人的には、ORMはクエリを意識しづらいし使いたくない。
リレーショナルモデルでは、正規化により重複を完全に除去して、結合して頑張ることが正しいとされている。
しかし、実際にはRDBMSは完全なリレーショナルモデルではなく、 結合操作によってパフォーマンスが出ないことがある。
そのために、あえて正規化をしない「非正規化」の存在を知った。 が、具体的にどの状況で使うのか良くわかっていない。
物理設計 FLOAT型は丸め誤差を避けられないので、科学演算でない限りはNUMERIC型を使う
マスタテーブルは参照テーブルにして、参照元から外部キー指定する トランザクション処理を考慮して、画像はBLOBとしてデータベース内部で管理する インデックスを貼る場合、闇雲に貼るのではなく、スロークエリログとクエリ実行計画をよく見てから考える 画像の扱い方に関して、最近はS3などのストレージに委譲することが多いため 一概には言えないと思った。
正直、アンビギュアスグループはよくわからなかった…。また読みます
クエリ NULLはUnknownであり、値ではない。NULLの代替を使うのはダメ パフォーマンスのために、全文検索はサードパーティのエンジンを使う DBへのアクセスは減らすべきだが、可読性・複雑性の緩和のために分割クエリを使う 列名は明示する なんでそもそもNULLが出てきたんだっけ？という問いに自身で明確に答えられなかったので、『理論から学ぶデータベース実践入門』を再読する必要がありそう。
アプリケーション セキュリティのためにパスワードはソルト足してハッシュ化、パスワードリセットはトークンで SQLインジェクションを防ぐためにプリペアドステートメントを使う データベースAPIの戻り値を確認 SQLも文章化・バージョン管理・テストをやる データベース処理をカプセル化するドメインモデルを用意する まとめ 冗長性を排除し、整合性を確保するのが正規化であるが、パフォーマンスは考慮していない。
基本的には整合性を考慮したテーブル設計・クエリ設計をすべきだが、規模感やパフォーマンスのため非正規化することもあり得る。
正規化段階はちゃんと覚える。</description></item><item><title>git challenge 4th で優勝してきた</title><link>https://itkq.jp/blog/2016/11/20/git-challenge/</link><pubDate>Sun, 20 Nov 2016 20:36:54 +0900</pubDate><guid>https://itkq.jp/blog/2016/11/20/git-challenge/</guid><description>git challenge 以前参加した逆求人イベントで、このコンテストをmixiの中の人に教えていただき、興味を持ったので参加した。
git challenge 2016.11.20
朝 会場はmixiのビルだった。
第4回git challengeがはじまりました。今日は快晴で、git challenge日和となりました。#mixi_git pic.twitter.com/0aIH0Au6uw
&amp;mdash; ミクシィグループ 新卒採用公式アカウント (@HR_mixi) 2016年11月20日
コンテストは2人組のチーム制で、チームは事前に決められていて、 逆求人イベントで一緒したラルフ氏 ( @r_ralph_h ) でした。他に顔見知りはいなかった。 コンテストのチュートリアルをやって、GithubにプッシュするとCIで採点、Slackに通知されるという流れを体験した。
昼 🍣 のスライドがあったものの、mixiでは 🍣 == 🍛 が true らしく、お昼ごはんはカレーだった。おいしかった。
コンテスト 戦略は特に無くて、奇数と偶数の問題をそれぞれが担当した。 問題内容は公開NGらしいので触れない。
コンテスト中はそれっぽいBGMが流れていたが、 全体的な解答ペースが早かったらしく、途中でPPAPなど妨害音楽に切り替わって険しかった。 不評を買ってか、その後九条カレンが登場したので良かった。
きんいろモザイク対応企業 #mixi_git pic.twitter.com/CF8JTOM4E1
&amp;mdash; いたこ (@itkq) 2016年11月20日
途中で詰まった問題はあったけれど、チームメイトが解いてくれた。神。 終盤の高難度問題は、解き方は見えたものの時間が足りなかった。
結果、同率1位で自分のチームを含めた3チームが優勝ということになった。 賞品は後で郵送してもらえるらしい。感謝。
（同着だったけど）優勝しました！！！ #mixi_git
&amp;mdash; いたこ (@itkq) 2016年11月20日
懇親会 作問者と会話して直接フィードバックできたり作問の裏話が聞けたので良かった。
まとめ 接戦だったので楽しかった。 治安のいいGit開発を心掛けたい。
チームメイトのエントリ ==&amp;gt; mixiのgit challengeに参加したお話
追記 賞品はメダルとOctcatくんでした。 でかい pic.</description></item><item><title>LaTeXiTのCLIみたいなのを書いた</title><link>https://itkq.jp/blog/2016/10/27/latexit%E3%81%AEcli%E3%81%BF%E3%81%9F%E3%81%84%E3%81%AA%E3%81%AE%E3%82%92%E6%9B%B8%E3%81%84%E3%81%9F/</link><pubDate>Thu, 27 Oct 2016 22:14:40 +0900</pubDate><guid>https://itkq.jp/blog/2016/10/27/latexit%E3%81%AEcli%E3%81%BF%E3%81%9F%E3%81%84%E3%81%AA%E3%81%AE%E3%82%92%E6%9B%B8%E3%81%84%E3%81%9F/</guid><description>LaTeXiT というTeX形式の数式を入力するとTeX形式の画像を出力するツールを知った．
研究発表のスライドを作る場合に，TeX形式の画像を貼り付けたいことがあり，早速インストールした．
最近のVim+LaTeX事情 に書いたように，最近はTexLiveのDockerイメージでLaTeX文書をコンパイルしている．
LaTeXiTのコンパイル設定をカスタマイズすれば対応できると思ったが，うまくいかなかった． コンパイルスクリプトでは，作業ディレクトリをマウントしてDockerイメージのコンパイルバイナリを走らせている．LaTeXiTが実行するコンパイルコマンドは，一時的に作成した /var/folders/&amp;hellip;/.tex を絶対参照しており，その部分は書き換えようがなかった．
LaTeXiTの動作は，コンパイル後にBounding boxを計算してトリミングして各種画像に変換する感じで作れそうだったのでCLIとして作った．
文字列をクリップボードにコピーする pbcopy は知っていたが，画像をコピーするものはないかと探したところ impbcopy があった． これを利用して，実行するとクリップボード中の文字列に対応するTeX形式の画像をクリップボードにコピーするので，サクッと使える感じになった．
本当はPopclipのExtensionとして作りたかったけどうまくいかなかった😇</description></item><item><title>夏休み読んだ本</title><link>https://itkq.jp/blog/2016/09/19/summer2016-reading/</link><pubDate>Mon, 19 Sep 2016 02:30:10 +0900</pubDate><guid>https://itkq.jp/blog/2016/09/19/summer2016-reading/</guid><description>今年の夏休みは本を読むぞと決めていたので成果を書く．
読了 &amp;ldquo;ファスト&amp;amp;スロー(上) あなたの意思はどのように決まるか?&amp;rdquo; 心理学の講義の課題図書．
人間の思考は，直感を生み出すシステム1(Fast)と直感の是非を論理的に判断するシステム2(Slow)の2つから構成される，という考え方を説明している．
統計を知っている学生や研究者でも，統計的事実に反する直感を否定しない場合があるというのが興味深かった．
この本を読むと，読む前より人間に対して寛容になれる気がする．
個人的には結構のめり込めた．
&amp;ldquo;アジャイルプラクティス 達人プログラマに学ぶ現場開発者の習慣&amp;rdquo; Webで技術書のレビューを眺めていたら半ば衝動的に購入した．
アジャイルを導入するために上司を説得する方法や，導入後にうまくやっていく方法が書いてあったと思う．
タイトルのプラクティスという単語で気づくべきだったが，先にアジャイルの概念を説明した本を購入すべきと先輩に言われた．
確かにアジャイルの概念を説明できなかった．
またいずれ読み直したい．
&amp;ldquo;コーディングを支える技術 〜成り立ちから学ぶプログラミング作法&amp;rdquo; プログラミングの本質を分かりやすく解説してくれている．易しい文章で読みやすかった．
エラー処理，例外のあたりが勉強になった．
プログラミングを始めたばかりの頃に読みたかった．
&amp;ldquo;インフラ/ネットワークエンジニアのためのネットワーク技術＆設計入門&amp;rdquo; 研究室の本棚にあったので読んでみた．
ある程度ネットワークの基本は研究室で学んできたので，ほとんど難なく読めた．
物理層のことももう少し分かるようになりたい．
&amp;ldquo;小説 君の名は。&amp;rdquo; 最高だった．
&amp;ldquo;君の名は。 Another Side:Earthbound&amp;rdquo; はい最高．
読み途中 &amp;ldquo;JUnit実践入門 〜体系的に学ぶユニットテストの技法&amp;rdquo; テストのプロに薦められたので読んでいる．
テストに関するプラクティスって独学だと厳しいのかもしれないという思いが漠然とあったけれど， 具体例も豊富だし，JUnitはあくまでツールであって，テストの本質を学べる良い本だと思う．
まだテストダブルが理解できていない気がする．
あとで読む &amp;ldquo;チーム開発実践入門 〜共同作業を円滑に行うツール・メソッド&amp;rdquo; ほしい物リストから送っていただいた本．
はやく読みたい．
&amp;ldquo;アジャイルレトロスペクティブズ　強いチームを育てる「ふりかえり」の手引き&amp;rdquo; アジャイルを理解するためにまずこっちから読む．
&amp;ldquo;人を動かす&amp;rdquo; なぜ購入したのかよく覚えていないけどお金を無駄にしないためにも読む．
所感 あと2冊ぐらいは読みたかった．</description></item><item><title>最近のVim&#43;LaTeX事情</title><link>https://itkq.jp/blog/2016/09/04/vim-latex/</link><pubDate>Sun, 04 Sep 2016 14:29:25 +0900</pubDate><guid>https://itkq.jp/blog/2016/09/04/vim-latex/</guid><description>メインで使っているのはMacBookPro Late 2013だが（そろそろ買い換えたい）， MacBookPro Early 2015をバイト先で支給されて自由に使えることになったので， LaTeX環境を構築しようと思った．
MacTexをインストールしようと思っていたけど，「それDockerでよくない？」と言われて確かに，となった．
なぜ今まで気が付かなかったんだろう．
&amp;ldquo;texlive docker&amp;rdquo; で適当に検索をかけると既存のイメージがヒットした．
harshjv/texlive-2015 public - Docker Hub
これをpullして手持ちの.texをコンパイルしてみると，includegraphicsで エラーを吐かれて画像が全く出力されなかった．
どうやらImageMagickあたりが足りていないようだったので， 必要なパッケージを追加インストールするだけのDockerfileを作ってビルドしたらコンパイル通った．
GitHub - itkq/docker-texlive2015
これまでVimでLaTeXのコンパイルは，Quickrunを使ってlatexmkを呼ぶように設定していた． そのため，Docker上のlatexmkを呼ぶように設定を変更する．
パスの通った場所に次のスクリプトを作成して実行権限を与える．
~/bin/latexmk
. ~/bin/docker-latex.sh init docker run --rm -v $(pwd):/var/texlive $(get_image_name) latexmk ~/bin/docker-latex.sh
#!/usr/bin/env bash function get_machine_name() { echo dev } function get_image_name() { echo texlive2015 } function init() { local MACHINE=$(get_machine_name) if ! docker-machine ls | grep $MACHINE | grep -q &amp;quot;Running&amp;quot;; then docker-machine start $MACHINE fi docker ps &amp;gt; /dev/null 2&amp;gt;&amp;amp;1 if [ $?</description></item><item><title>実用Git 読んだ</title><link>https://itkq.jp/blog/2016/04/04/%E5%AE%9F%E7%94%A8git-%E8%AA%AD%E3%82%93%E3%81%A0/</link><pubDate>Mon, 04 Apr 2016 02:20:25 +0900</pubDate><guid>https://itkq.jp/blog/2016/04/04/%E5%AE%9F%E7%94%A8git-%E8%AA%AD%E3%82%93%E3%81%A0/</guid><description>最近自分の Git に対する知識の無さを感じてきたので本を読もうと思っていたら、ちょうど借りる機会があったのでまとめた。Git コマンドの操作をより自信を持って行えるようになった気がする。
Git の基本的な概念 Git リポジトリは、作業ディレクトリと .git ディレクトリから成る。
git init により生成される Git リポジトリ (.git ディレクトリ) には、リビジョンと履歴の情報がすべて詰まっている。Git リポジトリが保持するデータ構造は、オブジェクト格納領域とインデックスの2つ。
Git オブジェクト Git オブジェクト格納領域は、オブジェクトの内容に SHA1 を適用して得られたハッシュ値から生成されるユニークな オブジェクト ID (名前) をもつ。 オブジェクト格納領域 (.git/objects) に配置される Git オブジェクトは、次の4種類である。
blob
ファイルの各バージョンは blob (binary large object) で表される。blob にはファイルのデータのみが含まれており、メタデータやファイル名は含まれていない。 Git はファイル名を気にしないため、同じ内容のファイルが複数あっても、それは1つの blob で表される。
tree
tree オブジェクトは、1階層分のディレクトリ情報を表現する。 tree は blob のオブジェクトID とパス名を持っている。 コミットが指す tree オブジェクトの ID さえ分かれば、再帰的に子の tree を辿ることで、そのコミットの状態のファイルをすべて取り出せる。
commit
コミットオブジェクトは、リポジトリに加えられた変更のメタデータを持つ。
tree の名前 新しいバージョンの作成者 (author) 作成された時間 新しいバージョンをリポジトリに置いた人 (comitter) リビジョンを作った理由の説明 (commit message) ルートコミット（最初のコミット）以外は1つ以上の親コミットIDをもつ。</description></item><item><title>2016年の抱負</title><link>https://itkq.jp/blog/2016/01/06/2016-goal/</link><pubDate>Wed, 06 Jan 2016 19:23:21 +0900</pubDate><guid>https://itkq.jp/blog/2016/01/06/2016-goal/</guid><description>英語を学ぶ 現時点の英語力 TOEICは800そこそこ、英検2級所持という尺度しか思いつかなかったが、理系大学4年生の平均は上回っているだろうか。
リーディング
技術系、特にプログラミングに関するの英文はゆっくりだが読める。その他の英文は積極的に避けたい気持ち。
リスニング
たまに何言ってるか分かるという感じ。
ライティング
高校生レベル。
スピーキング
中学生レベル。
なぜ英語 最近、「エンジニア」と「英語」をテーマとする記事が多数ホットエントリしているように感じる。 プログラミングをしていれば、英語のドキュメントを読む機会は多いだろうし、リーディングはあまり問題ないが、スピーキングとライティングがヤバイからなんとかしようみたいな内容だ。 確かに自分自身もヤバイ。
他にも、同級生でサンフランシスコに留学している人、留学の準備をしている人の存在も刺激になった。
どう学ぶか ライティングについては保留して、基本的にはリスニングとスピーキングを学ぶ方針とする。また、留学の予定はない。
大学編入の受験勉強時期に、東大を目指していた友人に薦められた英語の勉強法が海外ドラマ「Friends」だった。 内容は確かに面白かったが、成果が目に見えず、段々と見なくなってしまった。 受験勉強の息抜きに見ていた深夜アニメの方が面白かったからという見解も大いにある。 英語を聴く習慣をつけるためにも、Friends での英語学習を再開したい。
2015年のブックマーク数ランキングにランクインしていた 【無料】最強のオンライン英会話学習サイトVerblingをなぜ誰もオススメしないのか という記事で紹介されていた Verbling を試してみたら結構良さそうだった。モチベーションが維持できるかどうか。
エンジニアが0から英語を勉強する為にした事 で紹介されていたが、 英会話という手もあるらしい。がやってみる勇気が現状ではない。
とりあえず hulu に会員登録して Friends を見ようと思う。
関数型言語を学ぶ これまでの経験 高専の3年か4年の時に、Emacs Lisp を授業でほんのちょっとだけやって、cons セルは覚えた記憶がある。 完全に担当教員の趣味で教えられたんだと思う。
大学3年で、単位変換できなかった2年次の実験（ただのタイムアタック）を履修したが、 ここで Scheme を初めて使った。末尾再帰ぐらいまではそこそこに理解したが、 時間割の関係で、本来なら実験とセットで履修すべきプログラミングの講義を捨ててしまったためか、 以降（無限ストリームや継続）は十分に理解できないまま課題を消化していった。
関数型言語の特徴は分かったつもりであったが、現実の問題に対して 関数型言語ではどのように書くことができて、どこが優秀なのかがほとんどイメージできずにいた。 自主的に関数型言語を使ったことはなかったし、本当にただの「分かったつもり」だった。
なぜ関数型言語 現在配属している研究室が入っている西8号館で、LT が行われるとの情報を Twitter で仕入れたので、興味本位で参加した。 参加者のメインは M2 の先輩で、発表は興味深いし、発表の合間の議論も面白くて、尊敬できる人たちだった。
12月にあった LT では、Haskell の話があって、モナドって結局何なのとか、Optional 型がどうとか、Map と flatMap って何が違うのみたいな議論があった。 関数型言語の経験が乏しい僕はさっぱりだったが、そこで取り上げられていた問題がWebアプリだったので、 関数型言語でもWebアプリ書けるのか、という気持ちになった。</description></item><item><title>Tweetbot for Mac のツイート投稿画面でアカウントを切り替えるショートカット</title><link>https://itkq.jp/blog/2015/12/09/tweetbot-shortcut/</link><pubDate>Wed, 09 Dec 2015 04:08:58 +0900</pubDate><guid>https://itkq.jp/blog/2015/12/09/tweetbot-shortcut/</guid><description>経緯 複数アカウントを使う僕にとって重宝している Twitter クライアント「Tweetbot for Mac」だが、1つだけ弱点がある。 それは、ツイート投稿画面 (⌘+N) でアカウントの切り替え方法がマウスによる操作しかないことだ。
アイコンをクリック、screen_name を選択クリックの2ステップ必要になる。 折角 Global New Tweet Key を備えていても、マウス操作が必要になってしまう。
ということをぼやいていたら次のような意見を頂いた。
なるほどやってみることにした。
Twitter アイコンクリック
screen_name を選択して Enter
をショートカット1つで行う。
JavaScript for Automation (JXA) Apple Script という OS X 独自の自動化スクリプトがあるが、Yosemite (OS X 10.10) から JavaScript でも書けるようになったらしい。
Macのキーボード入力、マウスクリックをJavaScriptで (JXA) - Qiita を参考に、Tweetbot のツイート投稿画面の Twitter アイコンの UIElement をクリックしようとしたが、できなかった。 単純なボタンでの実装ではないからだろうか&amp;hellip;
cliclick マウス操作のエミュレータである cliclick を使うことにした。Homebrew でインストール。
$ brew install cliclick コマンドラインから、座標を与えることでマウス操作が行える。UIElement は position() で座標が取れるため、JXA と cliclick を組み合わせて自動化の見通しが立った。</description></item><item><title>学生枠でISUCON5に参加してみたら運良く予選を突破した</title><link>https://itkq.jp/blog/2015/10/09/isucon5-qualifier/</link><pubDate>Fri, 09 Oct 2015 11:25:38 +0900</pubDate><guid>https://itkq.jp/blog/2015/10/09/isucon5-qualifier/</guid><description>もう結構前のことになりますが、ISUCON5 というコンテストに参加しました。
書くことあんまりないからって書かないでいたらチームメイトから書くように煽られてしまったので書きます。
準備 バイト先の先輩である shiki に誘われて、その友人の @nemupm と僕 @itkq の 3人で参加することになった。 チーム名の「アジ・タコ・エンガワ！」は好きな寿司ネタを並べたものという設定で、僕はアジ（本当はタイが一番好きなんですが頭文字が被るのでやめました）。
コンテスト自体はなんとなく聞いたことある程度で、知識も経験もない僕は足手まといにならないか結構不安だった（先輩方は参加経験があった）。
担当は
インフラ
@nemupm
アプリ
shiki @itkq
に決まり、最初に話し合った時に、せっかくだから Golang でいってみようということになり、触ったことがなかった僕は Tour of a Go と build-web-application-with-golang を1週間ちょっとやって、なんとなく読める程度にした。
予選 まず MySQL と nginx のログとって Golang 実装のコード読んでどこが重いとか調べて作戦を立ててたら14時ぐらいになってて、ちょっと焦りつつもそこからアプリのチューニングを始めた。unix domain socket を使うとか定番のやつがあまり効かなくて、relations テーブルをメモリに載せる結構大きめな作業にとりかかることにした。
ダンプしたクエリを ruby で整形して/initializeで載せてアプリの SQL を取っ払ったら、スコアが5000ほど一気に伸びて一番盛り上がったし嬉しかった。
もう少し作業の余地はあったけど、Git 周りでうまくいかなかったり突然 Mac が落ちたりで焦って思ったように動けなくて本当申し訳なかった。
提出スコアが6000台で、終わった後に微妙そうって話をしてたけど、結果は5位でギリギリ本戦に出場できることになった！
終わりに 運営のみなさん本当にお疲れさまでした。本戦のほうもよろしくお願いします。
チームの先輩方ありがとうございました。予選は本当だめだめだったので本戦はもっと頑張りたいです。
あと @nemupm とは本戦で顔合わせなので楽しみです。
予選のリポジトリ: nemupm/isucon5-qualifier
以下チームメイトのエントリ:
ISUCON5予選 学生枠５位だけど突破できた
ISUCON予選を学生枠でギリギリ通過する技術</description></item><item><title/><link>https://itkq.jp/likes_and_dislikes/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://itkq.jp/likes_and_dislikes/</guid><description> 好き カロリーメイト (フルーツ味) 苦手 梅干し 紹興酒 麦焼酎 女性声優の隈を認識してしまうこと アレルギー そば (粉)</description></item><item><title/><link>https://itkq.jp/revision/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://itkq.jp/revision/</guid><description/></item></channel></rss>