<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Reading on itkq.jp</title><link>https://itkq.jp/tags/reading/</link><description>Recent content in Reading on itkq.jp</description><generator>Hugo -- gohugo.io</generator><language>ja-JP</language><lastBuildDate>Tue, 06 Mar 2018 00:24:12 +0900</lastBuildDate><atom:link href="https://itkq.jp/tags/reading/index.xml" rel="self" type="application/rss+xml"/><item><title>採用学を読んだ</title><link>https://itkq.jp/blog/2018/03/06/scientific-adopt/</link><pubDate>Tue, 06 Mar 2018 00:24:12 +0900</pubDate><guid>https://itkq.jp/blog/2018/03/06/scientific-adopt/</guid><description>採用学を読んだ。この本では、採用を定義した上で、現代の日本における採用事情の考察・最近の採用手法の変化・より良い採用のための考え方などが述べられており、一読すべき価値のある本だと思う。
この記事では、一応新卒採用を経験した身として、就活時に浮かんだいくつかの疑問を、採用学を読んで上で改めて考えていく。それが正解かどうかは分からない。書き終えてみると当たり前のことを言っているようにも見える。
新卒一括採用が一般的である理由 欧米では必要なときに必要な人材を雇用する「欠員補充」の採用が一般的なのに対し、なぜ日本ではある定められた時期に一斉に次の新社会人が就活をする「新卒一括採用」が一般的なのだろうか。
かつての国立大学は、就職先と密接に関係する、人材育成機関としての意味合い (たとえば旧帝国大学は官界へ、早慶ではビジネス方面へと輩出する) があった。コネクションに基づいた「推薦」による縁故採用 (現代の「学校推薦」とは異なる) であり、大学側と企業側のお互いの信頼関係による就職だったといえる。
定期一括採用が始まったのは今から100年ほど前の最近で、原因は経済成長と大正デモクラシーである、との引用があり、それまでは官界に行っていたような人たちも、銀行といった民間企業に就職し始めたのだという。
しかし「一括採用」の理由としては、本中の説明だけでは不十分に思える。Wikipedia の新卒一括採用のページが詳しかった。
1914年から第一次世界大戦が始まり日本は大戦景気に沸いたが、それによる人手不足から来る就職売り手市場によって学校卒業前に入社選考と採用を行う慣行が始まった[4]。 卒業前の採用慣行は第一次世界大戦後も続けられた。1927年には昭和金融恐慌と、それに続く世界恐慌から学生の就職難が社会問題となった（当時の映画「大学は出たけれど」も参照）。このような恐慌下で、1928年に三井三菱などの大手銀行を中心とする頭取重役の集まりである常盤会の意向により、大学および文部省に働きかけが行なわれ、翌年1929年の学生の定期採用は卒業後に行なうこととする協定が結ばれた[5][6]。就職協定の原型である。にもかかわらず、優秀な学生を確保したい企業による、学生の就職難への不安につけこんだ早期の選考は、この協定後も改まらなかった。その後景気が回復しても企業・学生双方による協定破りは絶えず、ついには1935年6月に三菱の提案で協定は正式に破棄されることとなった[7]。なお、今日まで使われる「内定」という言葉は、この協定によって使われるようになったのだと言われている[8]。つまりは、協定によって「採用決定」が卒業後ということに決められたため、在学中の事実上の採用決定を「内定」と呼ぶことになったのである。
第二次世界大戦終戦後も、大卒者の新卒一括採用の慣習は続いた。終戦直後の卒業生の就職は厳しかったようだが、翌年以降はそれほどでもなかったようである。敗戦という政治・経済状況に極限の変化を迫られる状況下においても、「卒業前の定期採用という慣行は、会社と大学にとってもはや変更不可能なまでに根づいていた[10]」のである。続いて起きた戦後復興と1950年に起きた朝鮮戦争は、日本国内に莫大な特需を生み出し、人手を必要とした企業は多くの新卒者を雇用した[11]。採用の早期化傾向に懸念を抱いた文部省は1953年6月に教育・財界関係者を集め懇談会を開き、「採用試験は10月中旬から1か月くらいとすること」を決定した。これが1996年まで続いた就職協定の始まりである[12]。しかし、就職協定は1996年の廃止に至るまで、ほぼ有名無実な協定であった。抜けがけ採用が発覚しても協定破り企業として新聞に公表されること以外にペナルティーがなく、企業側はマジメに就職協定を守っていては良い学生を採用することができなくなり、学生もそれに従わざるを得ないからである。特に1960年代からの高度経済成長期には更に採用が早期化し、大企業では卒業一年以上前の3年生の採用を決めるという事態にまで発展し、「青田買い」のみならず「早苗買い」「種もみ買い」とまで称されるほどになった[13]。以後も景気状況による変動はあるものの、基本的には在学中に採用が内定する状況は変化していない[14]。21世紀初頭現在においても状況はそれほど変わらず、大学生の就職活動は3年生の秋、9月から10月ごろに始まる。経団連の倫理憲章では、正式な内定日は10月1日[15]とされているが、内定の決定、いわゆる内々定は早ければ4年生になったばかりの春ごろから出され始める場合もある。
要約すると、20世紀の景気の変動と買い手市場によって、就職難の心理につけ込んだ、大学卒業前の優秀な学生の確保が加熱し、これを抑えるために文科省が採用試験の時期を線引した、ということになる。この歴史的経緯が現在でも普遍化しているのだろうが、そもそも大学を卒業したてで普通就労経験のない人間を採用する、「新卒採用」自体の目的はなんだろうか。
新卒採用の目的 就活時に考えていた、新卒採用 (ここでは特に初任給が一律のもの) の目的は、「近い将来成長の見込みがある人材を、手軽な賃金で雇い、会社の文化を十分に吸収させること」のように理解していた。新卒採用は、中途採用と比較して次の特徴があると考えていたからだ。
まだ芽が出ていない (が、近い将来芽が出る可能性がある) (そのため) 給料を安くできる 自社のカルチャーを馴染ませ易い この考えは、本で述べられている採用の1つ目の目的、
(1) 企業の目標および経営戦略実現のため
に近い。もう1つの目標は、
(2) 組織や職場を活性化させる
であり、多様化によって組織が均一化・硬直化することを避けることと述べられている。この2つはあくまで「採用」の目的であり、新卒採用よりも中途採用、すなわち多企業で培われた業務能力・カルチャーを持つ人材のほうが目的を達成するのではないか。
一般的に考えて、優先すべき目的は (1) である。(1) の達成のために人材が大幅に足りない企業、例えば
急激に成長している 従業員数が多い (1000~) ため相対的に離職者も多い は、(1) 達成の手段として新卒採用を用いることは合理的と言えそうだ。選考のプロセスで多様性を考慮できていれば同時に (2) の達成も見込まれる。次に、(2) 達成のために新卒採用をする企業は、
創業年数が長く従業員数もそれなりに多い などが挙げられそうだ。そのため、創業年数が短く従業員数も多くない中小企業 (ベンチャー企業?) が新卒採用を行うのには何か別の目的があると考えられる。
本中で述べられている一般的な新卒採用は、現時点での候補者の実務能力を測れないが故に、実務能力の期待を評価する。しかし、新卒の段階でも実務に直結する能力があれば新卒採用を行う理由として成立する。私が就職先として考えていた IT 業界 (いわゆる Web) では、PC を用いたプログラミングテストや面接でのコーディングが選考フローに組み込まれているのが普通だった。すなわちこの業界の新卒採用は、実務能力の期待しか測れない大部分の新卒採用と大きく体質が異なっている。</description></item><item><title>SQL実践入門 読んだ</title><link>https://itkq.jp/blog/2017/03/15/sql-practice/</link><pubDate>Wed, 15 Mar 2017 19:19:27 +0900</pubDate><guid>https://itkq.jp/blog/2017/03/15/sql-practice/</guid><description>メモです．
3章 式の条件分岐 SQLのパフォーマンスは，テーブルスキャンによる I/O を減らすことが重要． 手続き的な WHERE, UNION による条件分岐，テーブルフルスキャンが複数回行われる．同テーブル内では，SELECT 句で CASE WHEN で条件分岐させるとクエリの可読性，実行計画共に良くなることあるので，考えなしに UNION を使うのは危険． ただし，インデックスが使える場合は，「UNION による複数回のインデックススキャン」と「OR または IN による1回のフルスキャン」の勝負になり，UNION の方が速い場合もある． 4章 集約とカット GROUP BY には「集約」と「カット」の機能がある．「カット」とはパーティションをつくること．ウィンドウ関数の PARTITION BY はカットのための機能．
最近のオプティマイザは，GROUP BY による集約は，指定された列のハッシュ値によってグループ化している．古典的なソートより高速である． GROUP BY では，ハッシュかソートいずれの場合でも，メモリを多く使用するため，ワーキングメモリを使い切ってしまうこと（TEMP落ち）に注意． SELECT 句で指定するキーと，GROUP BY 句で指定するキーを同じくすることでカットできる． 5章 手続きSQL SQL実行のオーバーヘッド：
SQL文のネットワーク伝送 データベースへの接続 SQL文のパース SQL文の実行計画生成および評価 結果セットのネットワーク伝送 1と5は，同一ネットワーク上であればほぼ無視できる．2はコネクションプールで対応できる．このうち，3と4が支配的である． ある処理を達成するために，逐次的な「軽いSQL」によるロジックと，一度の「重いSQL」によるロジックがある．
軽いSQLによる問題：
DBのストレージは普通RAIDで構成され，I/O負荷を分散できるが，軽いSQLは，並列分散による恩恵が受けづらい DBは，重いSQLを高速化するように進化する．軽いSQLは_そもそもチューニングポテンシャルがない_ 一方で軽いSQLの利点：
実行計画が安定し，処理時間が相対的に見積もりやすい トランザクション粒度を調整できる 一撃でループ処理をするSQLの書き方：
ウィンドウ関数と CASE 式を使う CASE 式の WHEN は短絡評価 隣接リスト的なデータ構造に対しては，Recurvie Union による再帰クエリが有効 6章 結合 結合は3種類：</description></item><item><title>ウェブオペレーション 読んだ</title><link>https://itkq.jp/blog/2017/01/03/web-operations/</link><pubDate>Tue, 03 Jan 2017 15:30:11 +0900</pubDate><guid>https://itkq.jp/blog/2017/01/03/web-operations/</guid><description>結論としては、勉強になったし読み物として面白かった。
オペレーションに関係するソフトウェアの特徴・比較・使い方の詳細な記述はないが、 それらの関わりが簡潔にまとめられているおかげで、体系的な理解の助けになった。
この書籍は18の章から成っており、それぞれ著者が異なる。
ある章の結論が他の章の結論を直接的に否定しているわけではないが、 全体的には、ただ一つの正解は無いと言っているようで、考えさせられた。
内容が豊富で、すべては噛み砕けていないので、また読む。
データベース データベースは、難しいということが分かった。
データベースは特にボトルネックになりやすく、またバックアップが必要である。一般的なマスタスレーブ構成の場合、スレーブへの非同期レプリケーションは厳密には一貫性を失うし、マスタ冗長化もまた一貫性を失う。
じゃあクラスタリング、とはいかなくて、ウェブデータベースのユースケースに適したクラスタはないと書かれている。2016年現在も無いのかどうかは、ちょっとわからない。
CAP定理は、Consistency, Availability, Partition Tolerance の3つを同時に達成できないことを示す。 データを複数サーバに分割した場合、トランザクションの信頼性を保証するACID (Atomicity, Consistency, Isolation, Durability) 特性は失われる。また、分散トランザクションは通信障害の影響から確実性が保証されていない。
スケールが可能なNoSQLの採用も考慮すべきである。 NoSQLにも、アーキテクチャの違いから、色々ある。
Redisとmemcachedしか触ったことがなかったので、とりあえず他の種類と特徴ぐらいは覚えておきたい。
データベースアーキテクチャに正解はないので、論理的な選択が必要。
DevOps この本は2010年に出版されたものだが、2010年にもうDevOpsという言葉があったことに驚いた。
&amp;ldquo;DevOps&amp;quot;という単語が初出の発表(2009)では、開発と運用が互いのことを思いやるために、6つのツールと4つのカルチャーが挙げられていた。
自分の中では、DevOpsがすでに当たり前として受け入れてしまっているが、 これらのツールやカルチャーが無かった頃、そもそもなぜ開発と運用は分かれていたのだろうかと思った。 開発と運用が衝突する構図自体は理解できる。
雑に調べてみると、ITの内部統制によって、適切な権限管理の観点から、開発と運用を分離することが義務付けられているらしい。
アジャイル開発が積極的に用いられるようになってから、とにかく速くサイクルを回すために、自動テスト・継続的デプロイ・メトリクス可視化などの技術が発達し、それらの技術を共有するためのカルチャーも含めたプラクティスをDevOpsと呼ぶようになった、という感じなのだろうか。
最高のオペレーションとは アーキテクチャの設計では、その設計が5年後動作するのかを考えなければならない、と言っていた。 しかし、データベースアーキテクチャ設計では、シャーディングのような、将来のスケールを見越したアーキテクチャは、可能な限り使うな、と。
また、複雑なシステムは本質的に危険なので、シンプルにすべきであると言っている。しかし、「シンプル」なデータベースアーキテクチャは、現実的ではない、とも言っている。
すなわち、汎用的に正解であるアーキテクチャは存在しないということなのだろう。 あるシステム特有のアーキテクチャにするのが正解だと。 あれもこれもやりますみたいにサービスが進化していくのは良くない。
結局どう決めればいいのかは、SLAに基づく運用ポリシーよる。 するとSLAの決め方が重要になってくる。
Webシステムに必要なのは「一貫性」ではなく「可用性」と結論づけていた。 まずは顧客を継続的に留めることが重要である。 また、レスポンスタイムは顧客の印象評価に直結することが示されている。
ビジネス、マーケティング目線のメトリクスももちろん必要。 これらのメトリクスをベースにしてSLAを決定する。
オペレーションの仕事は、全てのアーキテクチャを正常に運用し、収集したメトリクスをステークホルダに翻訳すること。 ウェブオペレーションは、常に危険があり、「絶対」はない。 つまり、本質的には進化は無限に続くということで、 日々発展する技術、アーキテクチャ、メトリクスをキャッチアップする必要がある。
考えたこと 自分が考える、運用チーム(SRE)が存在する理由は、インフラをコード化し、プロダクションと等しい開発環境と素早い柔軟なデプロイを提供することで、開発にかかるオーバーヘッドを削減し、開発チームには創造的で生産的な業務に集中してもらうことだと考えていた。
DevOpsを成功させる鍵は、サービスの安定性は全員の責任と認識すること、と書かれていた。 また、「サイトの安定性の責任が運用チームだけのものではないとすると、従来の運用チームの役割は消えてしまうのか？」という疑問に対しては、「サイトを稼働させる専門家としての存在」と答えている。 運用チームは、最初にアラートを受け取り、プロダクションの問題の経験もあるサイトの安定性に絶えず提案する役割がある。 DevOpsによって、運用における運用チームの負担は確実に減る。 そこで、運用チームは、一時しのぎで障害に対応するのではなく、長期的に成長するインフラを管理するような本質的なタスクに集中できる。
「たった一度だけデプロイする」ことが目的なら、 インフラをコード化するオーバーヘッドは確実にあるため、 コード化するデメリットのほうが大きいかもしれない。 しかし、現実的には継続的にデプロイするし、DevOpsのデメリットは ほとんど無いように思う。
開発と運用がお互いに、真に生産的な業務を行うために、DevOpsはもっと当たり前になっていくだろう。
&amp;ldquo;アプリケーションはインフラであり、インフラはアプリケーションである&amp;rdquo; と書かれている通り、インフラレイヤーとアプリケーションレイヤーは近くなっている。 コードを書けないインフラ屋は必要とされない未来になると思うので、アプリケーションまで広く興味を持ち、コードを書けるようになりたい。</description></item><item><title>SQLアンチパターン 読んだ</title><link>https://itkq.jp/blog/2017/01/01/sql-antipattern/</link><pubDate>Sun, 01 Jan 2017 12:38:21 +0900</pubDate><guid>https://itkq.jp/blog/2017/01/01/sql-antipattern/</guid><description>インターネットに読めと言われている気がしたので読んだ。
論理設計 一意性と参照整合性に留意する。交差テーブルや従属テーブルを導入する。これは理解できた。
個人的には、ORMはクエリを意識しづらいし使いたくない。
リレーショナルモデルでは、正規化により重複を完全に除去して、結合して頑張ることが正しいとされている。
しかし、実際にはRDBMSは完全なリレーショナルモデルではなく、 結合操作によってパフォーマンスが出ないことがある。
そのために、あえて正規化をしない「非正規化」の存在を知った。 が、具体的にどの状況で使うのか良くわかっていない。
物理設計 FLOAT型は丸め誤差を避けられないので、科学演算でない限りはNUMERIC型を使う マスタテーブルは参照テーブルにして、参照元から外部キー指定する トランザクション処理を考慮して、画像はBLOBとしてデータベース内部で管理する インデックスを貼る場合、闇雲に貼るのではなく、スロークエリログとクエリ実行計画をよく見てから考える 画像の扱い方に関して、最近はS3などのストレージに委譲することが多いため 一概には言えないと思った。
正直、アンビギュアスグループはよくわからなかった…。また読みます
クエリ NULLはUnknownであり、値ではない。NULLの代替を使うのはダメ パフォーマンスのために、全文検索はサードパーティのエンジンを使う DBへのアクセスは減らすべきだが、可読性・複雑性の緩和のために分割クエリを使う 列名は明示する なんでそもそもNULLが出てきたんだっけ？という問いに自身で明確に答えられなかったので、『理論から学ぶデータベース実践入門』を再読する必要がありそう。
アプリケーション セキュリティのためにパスワードはソルト足してハッシュ化、パスワードリセットはトークンで SQLインジェクションを防ぐためにプリペアドステートメントを使う データベースAPIの戻り値を確認 SQLも文章化・バージョン管理・テストをやる データベース処理をカプセル化するドメインモデルを用意する まとめ 冗長性を排除し、整合性を確保するのが正規化であるが、パフォーマンスは考慮していない。
基本的には整合性を考慮したテーブル設計・クエリ設計をすべきだが、規模感やパフォーマンスのため非正規化することもあり得る。
正規化段階はちゃんと覚える。</description></item><item><title>夏休み読んだ本</title><link>https://itkq.jp/blog/2016/09/19/summer2016-reading/</link><pubDate>Mon, 19 Sep 2016 02:30:10 +0900</pubDate><guid>https://itkq.jp/blog/2016/09/19/summer2016-reading/</guid><description>今年の夏休みは本を読むぞと決めていたので成果を書く．
読了 &amp;ldquo;ファスト&amp;amp;スロー(上) あなたの意思はどのように決まるか?&amp;rdquo; 心理学の講義の課題図書．
人間の思考は，直感を生み出すシステム1(Fast)と直感の是非を論理的に判断するシステム2(Slow)の2つから構成される，という考え方を説明している．
統計を知っている学生や研究者でも，統計的事実に反する直感を否定しない場合があるというのが興味深かった．
この本を読むと，読む前より人間に対して寛容になれる気がする．
個人的には結構のめり込めた．
&amp;ldquo;アジャイルプラクティス 達人プログラマに学ぶ現場開発者の習慣&amp;rdquo; Webで技術書のレビューを眺めていたら半ば衝動的に購入した．
アジャイルを導入するために上司を説得する方法や，導入後にうまくやっていく方法が書いてあったと思う．
タイトルのプラクティスという単語で気づくべきだったが，先にアジャイルの概念を説明した本を購入すべきと先輩に言われた．
確かにアジャイルの概念を説明できなかった．
またいずれ読み直したい．
&amp;ldquo;コーディングを支える技術 〜成り立ちから学ぶプログラミング作法&amp;rdquo; プログラミングの本質を分かりやすく解説してくれている．易しい文章で読みやすかった．
エラー処理，例外のあたりが勉強になった．
プログラミングを始めたばかりの頃に読みたかった．
&amp;ldquo;インフラ/ネットワークエンジニアのためのネットワーク技術＆設計入門&amp;rdquo; 研究室の本棚にあったので読んでみた．
ある程度ネットワークの基本は研究室で学んできたので，ほとんど難なく読めた．
物理層のことももう少し分かるようになりたい．
&amp;ldquo;小説 君の名は。&amp;rdquo; 最高だった．
&amp;ldquo;君の名は。 Another Side:Earthbound&amp;rdquo; はい最高．
読み途中 &amp;ldquo;JUnit実践入門 〜体系的に学ぶユニットテストの技法&amp;rdquo; テストのプロに薦められたので読んでいる．
テストに関するプラクティスって独学だと厳しいのかもしれないという思いが漠然とあったけれど， 具体例も豊富だし，JUnitはあくまでツールであって，テストの本質を学べる良い本だと思う．
まだテストダブルが理解できていない気がする．
あとで読む &amp;ldquo;チーム開発実践入門 〜共同作業を円滑に行うツール・メソッド&amp;rdquo; ほしい物リストから送っていただいた本．
はやく読みたい．
&amp;ldquo;アジャイルレトロスペクティブズ　強いチームを育てる「ふりかえり」の手引き&amp;rdquo; アジャイルを理解するためにまずこっちから読む．
&amp;ldquo;人を動かす&amp;rdquo; なぜ購入したのかよく覚えていないけどお金を無駄にしないためにも読む．
所感 あと2冊ぐらいは読みたかった．</description></item><item><title>実用Git 読んだ</title><link>https://itkq.jp/blog/2016/04/04/%E5%AE%9F%E7%94%A8git-%E8%AA%AD%E3%82%93%E3%81%A0/</link><pubDate>Mon, 04 Apr 2016 02:20:25 +0900</pubDate><guid>https://itkq.jp/blog/2016/04/04/%E5%AE%9F%E7%94%A8git-%E8%AA%AD%E3%82%93%E3%81%A0/</guid><description>最近自分の Git に対する知識の無さを感じてきたので本を読もうと思っていたら、ちょうど借りる機会があったのでまとめた。Git コマンドの操作をより自信を持って行えるようになった気がする。
Git の基本的な概念 Git リポジトリは、作業ディレクトリと .git ディレクトリから成る。
git init により生成される Git リポジトリ (.git ディレクトリ) には、リビジョンと履歴の情報がすべて詰まっている。Git リポジトリが保持するデータ構造は、オブジェクト格納領域とインデックスの2つ。
Git オブジェクト Git オブジェクト格納領域は、オブジェクトの内容に SHA1 を適用して得られたハッシュ値から生成されるユニークな オブジェクト ID (名前) をもつ。 オブジェクト格納領域 (.git/objects) に配置される Git オブジェクトは、次の4種類である。
blob
ファイルの各バージョンは blob (binary large object) で表される。blob にはファイルのデータのみが含まれており、メタデータやファイル名は含まれていない。 Git はファイル名を気にしないため、同じ内容のファイルが複数あっても、それは1つの blob で表される。
tree
tree オブジェクトは、1階層分のディレクトリ情報を表現する。 tree は blob のオブジェクトID とパス名を持っている。 コミットが指す tree オブジェクトの ID さえ分かれば、再帰的に子の tree を辿ることで、そのコミットの状態のファイルをすべて取り出せる。
commit
コミットオブジェクトは、リポジトリに加えられた変更のメタデータを持つ。</description></item></channel></rss>